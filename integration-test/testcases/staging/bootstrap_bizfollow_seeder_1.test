# Test for bootstrap seeder
#  -. Start db relay
#  -. insert some data
#  -. start seeder, wait for it to finish
#  -. insert more data. so producer need catch up
#  -. start producer with seeding option
#  -. wait for the bootstrap
#  -. check consumer get the events
source setup_env.inc
db_config_file=${CONFIG_DIR_FROM_ROOT}/sources-bizfollow.json 
relay_event_dump_file=integration-test/var/work/bizfollow_relay_event_trace
# 10M buffer , event dump file 
$SCRIPT_DIR/dbus2_driver.py -c db_relay -o start --db_config_file=${db_config_file} --cmdline_props="databus.relay.eventBuffer.maxSize=102400;databus.relay.eventBuffer.scnIndexSize=10240;databus.relay.eventBuffer.trace.option=file;databus.relay.eventBuffer.trace.filename=${relay_event_dump_file};databus.relay.eventBuffer.trace.appendOnly=false" --jvm_direct_memory_size=10M

# reset the db and delete the checkpoints
$SCRIPT_DIR/dbus2_driver.py -c bootstrap_dbreset

# truncate, start db gen
$SCRIPT_DIR/dbus2_gen_event.py --db_gen -s bizfollow  --db_config_file=${db_config_file} --db_testdata_truncate --from_scn=1

db_insert_events() 
{
  num_batches=$1
  num_events_per_batch=$2
  num=1
  while [ "$num" -le "$num_batches" ]; do
    $SCRIPT_DIR/dbus2_gen_event.py -s bizfollow --db_testdata_insert --db_config_file=${db_config_file} --num_events=${num_events_per_batch}
    sleep 0.2
    let "num+=1"
  done
}
# insert events, multiple times, so we can have multiple windows
db_insert_events 10 10
#$SCRIPT_DIR/dbus2_gen_event.py -s bizfollow --db_testdata_insert --db_config_file=${db_config_file} --num_events=100

# start the producer, use a given port to avoid conflict with consumer
$SCRIPT_DIR/dbus2_driver.py -c bootstrap_seeder -o start -p integration-test/config/bootstrap-seeder-config-1.properties --db_config_file ${db_config_file}

source_id=`grep '"id"' ${VIEW_ROOT}/${db_config_file} | sed -e 's/^.*"id" : \([0-9]\{1,\}\),.*$/\1/'`
stat_txt="Test $0: After seeding. tab_${source_id} should have 100 rows"
ret=`mysql -uroot -Dbootstrap  -s --disable-column-names -e "select count(*) from tab_${source_id}"`
[[ $ret -eq 100 ]]
source report_pass_fail.inc
echo number of rows in tab_${source_id} = $ret
# print the state
mysql -uroot -Dbootstrap -vvv -e "select * from bootstrap_sources; select * from bootstrap_loginfo; select * from bootstrap_applier_state; select * from bootstrap_producer_state; select * from bootstrap_seeder_state;"

# insert events
#$SCRIPT_DIR/dbus2_gen_event.py -s bizfollow --db_testdata_insert --db_config_file=${db_config_file} --num_events=100
db_insert_events 10 10

# start the bootstrap server before producer and make sure it is not serving traffic during seeding catch up
$SCRIPT_DIR/dbus2_driver.py -c bootstrap_server -o start

# start producer with seed state check enabled
$SCRIPT_DIR/dbus2_driver.py -c test_bootstrap_producer -o start --cmdline_props="databus.bootstrap.bootstrapDBStateCheck=true;databus.bootstrap.client.runtime.relay(1).sources=com.linkedin.events.bizfollow.bizfollow.BizFollow;databus.bootstrap.client.container.httpPort=9067;databus.bootstrap.client.checkpointPersistence.fileSystem.rootDirectory=./bootstrap-checkpoints;databus.bootstrap.client.checkpointPersistence.clearBeforeUse=true;databus.bootstrap.client.connectionDefaults.eventBuffer.maxSize=10240000;databus.bootstrap.client.connectionDefaults.eventBuffer.allocationPolicy=DIRECT_MEMORY;databus.bootstrap.client.connectionDefaults.eventBuffer.queuePolicy=BLOCK_ON_WRITE;databus.bootstrap.client.connectionDefaults.eventBuffer.readBufferSize=1024000;databus.bootstrap.client.connectionDefaults.eventBuffer.scnIndexSize=1024000"

# start the consumer. 
# !! This must be after seeding finish or it will get an excpetion from bootstrap_server and get into pause state
consumer_1_log=${WORK_DIR_FROM_ROOT}/bizfollow_consumer_1.events
consumer_1_value_log=${WORK_DIR_FROM_ROOT}/bizfollow_consumer_1.values
$SCRIPT_DIR/dbus2_driver.py -c bizfollow_consumer -o start --dump_file=${consumer_1_log}  --value_file=${consumer_1_value_log} --bootstrap_port=6060 --cmdline_props="databus.client.connectionDefaults.eventBuffer.maxSize=10240000;databus.client.connectionDefaults.eventBuffer.scnIndexSize=1024000;databus.client.connectionDefaults.eventBuffer.readBufferSize=1024000;databus.client.checkpointPersistence.fileSystem.rootDirectory=./bfclient1-checkpoints;databus.client.checkpointPersistence.clearBeforeUse=true"

# insert more events
#$SCRIPT_DIR/dbus2_gen_event.py -s bizfollow --db_testdata_insert --db_config_file=${db_config_file} --num_events=100
db_insert_events 10 10

# wait for bootstrap to finish
$SCRIPT_DIR/dbus2_driver.py -c bizfollow_consumer -o wait_event_bootstrap --timeout=40

# look at the log, there should be some SCN not found errors
echo ==GREP ERROR
ls -1tr $LOG_DIR/default_*_relay_start* | ${TAIL_PATH} -n 1 | xargs grep ERROR
ls -1tr $LOG_DIR/default_*_consumer_start* | ${TAIL_PATH} -n 1 | xargs grep "Bootstrap completed"

# the seeder put the sequence for all the seeding rows as the last windowscn, so try to ignore sequence or just compare the later events
stat_txt="Test $0. Step 1. Get all the events"
echo ==$stat_txt :Compare JSON
$SCRIPT_DIR/dbus2_json_compare.py -c --sort_key --ignored_columns=sequence,traceEnabled,timestampInNanos -s $VIEW_ROOT/${relay_event_dump_file} ${consumer_1_log}
source report_pass_fail.inc

stat_txt="Test $0. Step 2. All the events from event buffer."
echo ==$stat_txt 
$SCRIPT_DIR/dbus2_json_compare.py -c --sort_key --keyMin=100 --keyMax=3000 --enable_consumer_key_range $VIEW_ROOT/${relay_event_dump_file} ${consumer_1_log}

#compare result
stat_txt="Test $0 Step 3. Compare with db"
final_report=1
$SCRIPT_DIR/dbus2_json_compare.py  -c --sort_key --db_src_ids=${source_id} --db_config_file=${db_config_file} ${consumer_1_value_log}
source report_pass_fail.inc

# stop
$SCRIPT_DIR/dbus2_driver.py -c bizfollow_consumer -o stop
$SCRIPT_DIR/dbus2_driver.py -c bootstrap_server -o stop
$SCRIPT_DIR/dbus2_driver.py -c test_bootstrap_producer -o stop
$SCRIPT_DIR/dbus2_driver.py -c db_relay -o stop

exit $all_stat
