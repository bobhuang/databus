#!/bin/bash
# CHO testing
#   This is using the network client
#   -. start 3 shared network clients and point to the same relay and bootstrap
#   -. round robin kill client
#   -. accumulate events and make sure there are no gaps in between

#cd $HOME/project/databus2/integration-test/testcases
#source $HOME/.bashrc
#source $HOME/.profile
#source $HOME/.profile_custom
source setup_env.inc
#relay_event_dump_file=integration-test/var/work/bizfollow_relay_event_trace
#$SCRIPT_DIR/dbus2_driver.py -c bizfollow_relay -o start --cmdline_props="databus.relay.eventBuffer.maxSize=1024000;databus.relay.eventBuffer.scnIndexSize=102400;databus.relay.eventBuffer.trace.option=file;databus.relay.eventBuffer.trace.filename=${relay_event_dump_file};databus.relay.eventBuffer.trace.appendOnly=false" --jvm_direct_memory_size=10M

zookeeper_server_ports="esv4-be40:2181,esv4-be41:2182,esv4-be42:2183"
# default datadir integration_test/var/work/zookeeper/data/1
# start the zookeeper cluster

hostname=`/bin/hostname`
my_zookeeper_id=1
case "$hostname" in
  "esv4-be40.corp" ) my_zookeeper_id=1 ;;
  "esv4-be41.corp" ) my_zookeeper_id=2 ;;
  "esv4-be42.corp" ) my_zookeeper_id=3 ;;
esac

#$SCRIPT_DIR/dbus2_driver.py -c zookeeper -o start --zookeeper_reset --zookeeper_server_ports=${zookeeper_server_ports} --zookeeper_server_ids=${my_zookeeper_id} --cmdline_props="tickTime=2000;initLimit=5;syncLimit=2" 
#$SCRIPT_DIR/dbus2_driver.py -c zookeeper -o cmd --zookeeper_server_ports=${zookeeper_server_ports} --zookeeper_cmds="ls /"
# server port server.1=localhost:2800:3800 server.2=localhost:2801:3801 server.3=localhost:2802:3802# start the consumer
#sleep 10

# do a sync at this point

# start three clients
start_consumer_port=8090
relay_host=esv4-be38
relay_port=9090
bootstrap_host=esv4-be39
bootstrap_port=6161
total_num_consumers=3

#cnt=1
#while [ $cnt -lt $total_num_consumers]; do
#  consumer_log=${WORK_DIR_FROM_ROOT}/bizfollow_consumer_${cnt}.events
#  consumer_port=$(($start_consumer_port+1))
#  $SCRIPT_DIR/dbus2_driver.py -c bizfollow_consumer -o start --logfile=$consumer_server_log --relay_host=$relay_host --bootstrap_host=$bootstrap_host --dump_file=${consumer_log} --http_port=${consumer_port} -cmdline_props="databus.client.connectionDefaults.eventBuffer.maxSize=10240000;databus.client.connectionDefaults.eventBuffer.allocationPolicy=DIRECT_MEMORY;databus.client.connectionDefaults.eventBuffer.queuePolicy=BLOCK_ON_WRITE;databus.client.connectionDefaults.eventBuffer.readBufferSize=1024000;databus.client.connectionDefaults.eventBuffer.scnIndexSize=1024000;databus.client.cluster.enabled=true;databus.client.cluster.clusterServerList=${zookeeper_server_ports};databus.client.checkpointPersistence.type=SHARED"
#  cnt=$(($cnt+1))
#done

# start the first consumer
#VIEW_ROOT=$HOME/project/databus2

# remote the checkpoint dir
# /Databus-Client-Domain/groups/default-databus-group/shareddata
#$SCRIPT_DIR/dbus2_driver.py -c zookeeper -o cmd --zookeeper_cmd="delete /Databus-Client-Domain

NETWORK_ROOT=$HOME/project/network
consumer_log_combined=$VIEW_ROOT/${WORK_DIR_FROM_ROOT}/bizfollow_consumer_combined.events
rm -rf $consumer_log_combined
cnt=1
total_cnt=1

random_interval=360
#test_only=echo
while [ 1 ]; do
  if [ $cnt -ne $my_zookeeper_id ]; then 
    cnt=$(($cnt % $total_num_consumers + 1))
    total_cnt=$(($total_cnt+1))
    continue
  fi
  #consumer_log=${WORK_DIR_FROM_ROOT}/bizfollow_consumer_${cnt}.events
  #consumer_port=$(($start_consumer_port+$cnt))
  #consumer_server_log=${VIEW_ROOT}/${LOG_DIR_FROM_ROOT}/bizfollow_consumer_${cnt}_`date +%Y_%m_%d_%H_%M_%S`.log 
  if [ $total_cnt -gt $total_num_consumers ]; then
    # make this long as voldemort is slow to update
    sleep $(($RANDOM % $random_interval + 1200))
    #echo == `date` >> $consumer_log_combined
    #cat $VIEW_ROOT/$consumer_log >> $consumer_log_combined
    #$SCRIPT_DIR/dbus2_driver.py -c bizfollow_consumer -o shutdown_force --http_port=${consumer_port}
    # stop
    cur_dir=`pwd`
    cd $NETWORK_ROOT
    echo == `date`
    #$test_only ant -f tools.xml bizfollow-ds.undeploy 2>&1 >> ${consumer_log_combined}
    $test_only ant -f tools.xml backend-container.stop 2>&1 >> ${consumer_log_combined}
    pid=`cat $NETWORK_ROOT/dist/backend-container/logs/backend-container.pid | cut -f2 -d\=`
    kill -9 $pid
    sleep 1
    cd $cur_dir
    echo == `date` >> $consumer_log_combined
    #echo == consumer $cnt killed >> $consumer_log_combined
    sleep $(($RANDOM % $(($random_interval/6)) + 1))
  fi
  # restart
  cur_dir=`pwd`
  cd $NETWORK_ROOT
  # do this only at the beginning
  echo == `date`
  $test_only ant -f tools.xml backend-container.start 2>&1 >> ${consumer_log_combined}
  if [ $total_cnt -le $total_num_consumers ]; then
    $test_only cp -rf $VIEW_ROOT/schemas_registry $NETWORK_ROOT/dist/backend-container  2>&1 >> ${consumer_log_combined}
    #$test_only ant -f tools.xml voldemort.deploy 2>&1 >> ${consumer_log_combined}
    $test_only ant -f tools.xml bizfollow-ds.deploy 2>&1 >> ${consumer_log_combined}
    #$test_only ant -f tools.xml bizfollow-ds-databus2.deploy 2>&1 >> ${consumer_log_combined}
  fi
  #$test_only ant -f tools.xml bizfollow-ds.deploy 2>&1 >> ${consumer_log_combined}
  cd $cur_dir
  cnt=$(($cnt % $total_num_consumers + 1))
  total_cnt=$(($total_cnt+1))
  #$test_only $SCRIPT_DIR/dbus2_driver.py -c bizfollow_consumer -o start --logfile=$consumer_server_log --relay_host=$relay_host --relay_port=$relay_port --bootstrap_host=$bootstrap_host --bootstrap_port=$bootstrap_port --dump_file=${consumer_log} --http_port=${consumer_port} --cmdline_props="databus.client.connectionDefaults.eventBuffer.maxSize=10240000;databus.client.connectionDefaults.eventBuffer.allocationPolicy=DIRECT_MEMORY;databus.client.connectionDefaults.eventBuffer.queuePolicy=BLOCK_ON_WRITE;databus.client.connectionDefaults.eventBuffer.readBufferSize=1024000;databus.client.connectionDefaults.eventBuffer.scnIndexSize=1024000;databus.client.cluster.enabled=true;databus.client.cluster.clusterServerList=${zookeeper_server_ports};databus.client.checkpointPersistence.type=SHARED"
done

exit 0
