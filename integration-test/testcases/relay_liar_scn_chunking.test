#!/bin/bash
#******************************************************
# set TEST_NAME before calling setup_env.inc
#******************************************************
# simple bootstrap test, generate random event, put that in bootstrap
export TEST_NAME=relay_liar_scn_chunking.test
#******************************************************
# sets up common environmnet variables and 
source setup_env.inc

#***************************************************************************************************************************************
#all ${ALL_CAPS} type vars come from setup_env.inc(except TEST_NAME)...check that file first before introducing any new variables here
#***************************************************************************************************************************************
relay_port_1=${RELAY_PORT_BASE}
let relay_port_2="${RELAY_PORT_BASE} + 1"
let relay_port_3="${RELAY_PORT_BASE} + 2"
client_port_1=${CLIENT_PORT_BASE}
let client_port_2="${CLIENT_PORT_BASE} + 1"
let client_port_3="${CLIENT_PORT_BASE} + 2"
relay_event_dump_file_1=${WORK_DIR_FROM_ROOT}/liar_relay_event_trace_1
relay_event_dump_file_2=${WORK_DIR_FROM_ROOT}/liar_relay_event_trace_2
relay_event_dump_file_3=${WORK_DIR_FROM_ROOT}/liar_relay_event_trace_3
consumer_1_log=${WORK_DIR_FROM_ROOT}/liar_consumer_1.events
consumer_1_value_log=${WORK_DIR_FROM_ROOT}/liar_consumer_1.values
consumer_2_log=${WORK_DIR_FROM_ROOT}/liar_consumer_2.events
consumer_2_value_log=${WORK_DIR_FROM_ROOT}/liar_consumer_2.values
consumer_3_log=${WORK_DIR_FROM_ROOT}/liar_consumer_3.events
consumer_3_value_log=${WORK_DIR_FROM_ROOT}/liar_consumer_3.values
db_config_file=config/sources-liar.json
db_config_file_2=config/sources-liar-scn-chunk-1.json
relay1_maxscn_dir=${VIEW_ROOT}/${WORK_DIR_FROM_ROOT}/maxScn1
relay2_maxscn_dir=${VIEW_ROOT}/${WORK_DIR_FROM_ROOT}/maxScn2
relay3_maxscn_dir=${VIEW_ROOT}/${WORK_DIR_FROM_ROOT}/maxScn3
relay_1_server_log=${VIEW_ROOT}/${LOG_DIR_FROM_ROOT}/liar_relay_${relay_port_1}_`date +%Y_%m_%d_%H_%M_%S`.log
relay_2_server_log=${VIEW_ROOT}/${LOG_DIR_FROM_ROOT}/liar_relay_${relay_port_2}_`date +%Y_%m_%d_%H_%M_%S`.log
relay_3_server_log=${VIEW_ROOT}/${LOG_DIR_FROM_ROOT}/liar_relay_${relay_port_3}_`date +%Y_%m_%d_%H_%M_%S`.log

# truncate
$SCRIPT_DIR/dbus2_gen_event.py -s liar  --db_config_file=${db_config_file} --db_testdata_truncate --debug

# 10M buffer , event dump file relay 1
$SCRIPT_DIR/dbus2_driver.py -c db_relay -o start --db_config_file=${db_config_file} --logfile=${relay_1_server_log} --cmdline_props="databus.relay.eventBuffer.maxSize=10240000;databus.relay.eventBuffer.scnIndexSize=10240;databus.relay.eventBuffer.trace.option=file;databus.relay.eventBuffer.trace.filename=${relay_event_dump_file_1};databus.relay.eventBuffer.trace.appendOnly=false;databus.relay.container.httpPort=${relay_port_1};databus.relay.container.jmx.jmxServicePort=19998;databus.relay.dataSources.sequenceNumbersHandler.file.scnDir=${relay1_maxscn_dir}" --jvm_direct_memory_size=30M  -l config/client-log4j2file.properties.debug

# 10M buffer , event dump file relay 2
$SCRIPT_DIR/dbus2_driver.py -c db_relay -o start --db_config_file=${db_config_file_2} --logfile=${relay_2_server_log} --cmdline_props="databus.relay.eventBuffer.maxSize=10240000;databus.relay.eventBuffer.scnIndexSize=10240;databus.relay.eventBuffer.trace.option=file;databus.relay.eventBuffer.trace.filename=${relay_event_dump_file_2};databus.relay.eventBuffer.trace.appendOnly=false;databus.relay.container.httpPort=${relay_port_2};databus.relay.container.jmx.jmxServicePort=19999;databus.relay.dataSources.sequenceNumbersHandler.file.scnDir=${relay2_maxscn_dir}" --jvm_direct_memory_size=30M  -l config/client-log4j2file.properties.debug

# 10M buffer , event dump file relay 3
$SCRIPT_DIR/dbus2_driver.py -c db_relay -o start --db_config_file=${db_config_file_2} --logfile=${relay_3_server_log} --cmdline_props="databus.relay.eventBuffer.maxSize=10240000;databus.relay.eventBuffer.scnIndexSize=10240;databus.relay.eventBuffer.trace.option=file;databus.relay.eventBuffer.trace.filename=${relay_event_dump_file_3};databus.relay.eventBuffer.trace.appendOnly=false;databus.relay.container.httpPort=${relay_port_3};databus.relay.container.jmx.jmxServicePort=19997;databus.relay.dataSources.sequenceNumbersHandler.file.scnDir=${relay3_maxscn_dir}" --jvm_direct_memory_size=30M  -l config/client-log4j2file.properties.debug

DB_MAXSCN=`echo 'select CURRENT_SCN from v$database;' | sqlplus -S liar/liar@DB  | tail -2 | head -1 | perl -lane '{my $a = $_; $a =~ s/\D*(\d+)\D*/$1/g; print "$a";} '`;

let relay_start_Scn="${DB_MAXSCN} - 50"
echo "DB Max SCN is : ${DB_MAXSCN} , Relay_start_Scn : ${relay_start_Scn}";

# start the consumer1
$SCRIPT_DIR/dbus2_driver.py -c liar_consumer -o start --dump_file=${consumer_1_log}  --value_file=${consumer_1_value_log} --http_port=${client_port_1} --relay_port=${relay_port_1} --cmdline_props="databus.client.connectionDefaults.eventBuffer.maxSize=10240000;databus.client.connectionDefaults.eventBuffer.scnIndexSize=1024000;databus.client.connectionDefaults.eventBuffer.readBufferSize=1024000;databus.client.checkpointPersistence.fileSystem.rootDirectory=./liarclient-checkpoints1;databus.client.checkpointPersistence.clearBeforeUse=true;databus.client.connectionDefaults.enablePullerMessageQueueLogging=true;"

# start the consumer2
$SCRIPT_DIR/dbus2_driver.py -c liar_consumer -o start --dump_file=${consumer_2_log}  --value_file=${consumer_2_value_log} --http_port=${client_port_2} --relay_port=${relay_port_2} --cmdline_props="databus.client.connectionDefaults.eventBuffer.maxSize=10240000;databus.client.connectionDefaults.eventBuffer.scnIndexSize=1024000;databus.client.connectionDefaults.eventBuffer.readBufferSize=1024000;databus.client.checkpointPersistence.fileSystem.rootDirectory=./liarclient-checkpoints2;databus.client.checkpointPersistence.clearBeforeUse=true;databus.client.connectionDefaults.enablePullerMessageQueueLogging=true;"

# start the consumer3
$SCRIPT_DIR/dbus2_driver.py -c liar_consumer -o start --dump_file=${consumer_3_log}  --value_file=${consumer_3_value_log} --http_port=${client_port_3} --relay_port=${relay_port_3} --cmdline_props="databus.client.connectionDefaults.eventBuffer.maxSize=10240000;databus.client.connectionDefaults.eventBuffer.scnIndexSize=1024000;databus.client.connectionDefaults.eventBuffer.readBufferSize=1024000;databus.client.checkpointPersistence.fileSystem.rootDirectory=./liarclient-checkpoints2;databus.client.checkpointPersistence.clearBeforeUse=true;databus.client.connectionDefaults.enablePullerMessageQueueLogging=true;"

#Set startScn
$SCRIPT_DIR/dbus2_gen_event.py --db_gen -s liar  --db_config_file=${db_config_file} --from_scn=${relay_start_Scn} --server_port=${relay_port_1} --debug
$SCRIPT_DIR/dbus2_gen_event.py --db_gen -s liar  --db_config_file=${db_config_file_2} --from_scn=${relay_start_Scn} --server_port=${relay_port_2} --debug

# Generate events
$SCRIPT_DIR/dbus2_gen_event.py -s liar --db_testdata_insert --db_config_file=${db_config_file} --num_events=50 --server_port=${relay_port_1}  --debug
$SCRIPT_DIR/dbus2_gen_event.py -s liar --db_testdata_insert --db_config_file=${db_config_file_2} --num_events=50 --server_port=${relay_port_2} --debug
echo "Sleep for 10 sec"
sleep 10;

#wait for both consumer 1 and consumer 2 to catchup
$SCRIPT_DIR/dbus2_driver.py -c liar_consumer -o wait_event --timeout=60 --http_port=${client_port_1} --relay_port=${relay_port_1}
$SCRIPT_DIR/dbus2_driver.py -c liar_consumer -o wait_event --timeout=60 --http_port=${client_port_2} --relay_port=${relay_port_2}

MIN_TXLOG_SCN=`echo 'select min(tx.ora_rowscn) from sy$txlog tx;' | sqlplus -S liar/liar@DB  | tail -2 | head -1 | perl -lane '{my $a = $_; $a =~ s/\D*(\d+)\D*/$1/g; print "$a";} ';`
let relay_start_Scn2="${MIN_TXLOG_SCN} - 20000";
echo "MIN_TXLOG_SCN : ${MIN_TXLOG_SCN} , Relay_start_Scn : ${relay_start_Scn2}";

#Set startScn for relay3
$SCRIPT_DIR/dbus2_gen_event.py --db_gen -s liar  --db_config_file=${db_config_file_2} --from_scn=${relay_start_Scn2} --server_port=${relay_port_3} --debug

echo "Sleep for 10 sec"
sleep 10;

#wait for both consumer 3 to catchup
$SCRIPT_DIR/dbus2_driver.py -c liar_consumer -o wait_event --timeout=60 --http_port=${client_port_3} --relay_port=${relay_port_3}

echo "Verifying if SCN Chunking has been enabled"
stat_txt="Test $0 Verifying if SCN Chunking has been enabled"
grep "Enabling chunking for source" ${relay_2_server_log} | wc -l | perl -lane '{ my $a = $_; chomp($a); if ($a != 1 ) { print $a; exit 1; } else { exit 0;} }'
source report_pass_fail.inc

echo "Verifying if SCN Chunking has been disabled"
stat_txt="Test $0 Verifying if SCN Chunking has been disabled"
grep "Disabling chunking for source" ${relay_2_server_log} | wc -l | perl -lane '{ my $a = $_; chomp($a); if ($a != 1 ) { print $a; exit 1; } else { exit 0;} }'
source report_pass_fail.inc

echo "Verifying if SCN Chunking has been enabled in relay 3"
stat_txt="Test $0 Verifying if SCN Chunking has been enabled in relay 3"
grep "Enabling chunking for source" ${relay_3_server_log} | wc -l | perl -lane '{ my $a = $_; chomp($a); if ($a != 1 ) { print $a; exit 1; } else { exit 0;} }'
source report_pass_fail.inc

echo "Verifying if SCN Chunking has been disabled in relay 3"
stat_txt="Test $0 Verifying if SCN Chunking has been disabled in relay 3"
grep "Disabling chunking for source" ${relay_3_server_log} | wc -l | perl -lane '{ my $a = $_; chomp($a); if ($a != 1 ) { print $a; exit 1; } else { exit 0;} }'
source report_pass_fail.inc

echo "Pausing Chunked Relay"
$SCRIPT_DIR/dbus2_gen_event.py --db_gen --suspend_gen --src_ids=20,21 --server_port=${relay_port_2} --debug

echo "Generating more events"
$SCRIPT_DIR/dbus2_gen_event.py -s liar --db_testdata_insert --db_config_file=${db_config_file} --num_events=50 --server_port=${relay_port_1}  --debug

echo "Sleep for 10 sec"
sleep 10;

echo "Resetting Catchup SCN" 
resetOutput=`curl "http://localhost:9001/testOracleProducer/resetCatchupScn"`
echo "Resetting Catchup SCN output : ${resetOutput}";

echo "Sleep for 10 sec"
sleep 10;

echo "Resuming Chunked Relay"
$SCRIPT_DIR/dbus2_gen_event.py --db_gen --src_ids=20,21 --resume_gen --server_port=${relay_port_2} --debug

echo "Sleep for 30 sec"
sleep 30;

#wait for both consumer 1 and consumer 2 to catchup
$SCRIPT_DIR/dbus2_driver.py -c liar_consumer -o wait_event --timeout=60 --http_port=${client_port_1} --relay_port=${relay_port_1}
$SCRIPT_DIR/dbus2_driver.py -c liar_consumer -o wait_event --timeout=60 --http_port=${client_port_2} --relay_port=${relay_port_2}

echo "2 Verifying if SCN Chunking has been enabled again"
stat_txt="Test $0 2 Verifying if SCN Chunking has been enabled again"
grep "Enabling chunking for source" ${relay_2_server_log} | wc -l | perl -lane '{ my $a = $_; chomp($a); if ($a != 2 ) { print $a; exit 1; } else { exit 0;} }'
source report_pass_fail.inc

echo "2 Verifying if SCN Chunking has been disabled again"
stat_txt="Test $0 2 Verifying if SCN Chunking has been disabled again"
grep "Disabling chunking for source" ${relay_2_server_log} | wc -l | perl -lane '{ my $a = $_; chomp($a); if ($a != 2 ) { print $a; exit 1; } else { exit 0;} }'
source report_pass_fail.inc

echo "Verifying if Regular Query was used for fetching liar_job_relay"
stat_txt="Verifying if Regular Query was used for fetching liar_job_relay"
grep  "select /\*+ first_rows LEADING[(]tx[)] \*/ liar.sync_core.getScn[(]tx.scn, tx.ora_rowscn[)] scn, tx.ts event_timestamp, src.\* from liar.sy\$liar_job_relay_2 src, liar.sy\$txlog tx where src.txn=tx.txn and tx.scn > [?] and tx.ora_rowscn > [?]; skipInfinityScn=false" ${relay_2_server_log} | wc -l | perl -lane '{ my $a = $_; chomp($a); if ($a <= 0 ) { print $a; exit 1; } else { exit 0;} }'
source report_pass_fail.inc

echo "Verifying if Regular Query was used for fetching liar_member_relay"
stat_txt="Verifying if Regular Query was used for fetching liar_member_relay"
grep  "select /\*+ first_rows LEADING[(]tx[)] \*/ liar.sync_core.getScn[(]tx.scn, tx.ora_rowscn[)] scn, tx.ts event_timestamp, src.\* from liar.sy\$liar_member_relay src, liar.sy\$txlog tx where src.txn=tx.txn and tx.scn > [?] and tx.ora_rowscn > [?]; skipInfinityScn=false" ${relay_2_server_log} | wc -l | perl -lane '{ my $a = $_; chomp($a); if ($a <= 0 ) { print $a; exit 1; } else { exit 0;} }'
source report_pass_fail.inc


echo "Verifying if SCN Chunked Query was used for fetching liar_job_relay"
stat_txt="Verifying if SCN Chunked Query was used for fetching liar_job_relay"
grep  'SELECT /\*+ first_rows LEADING[(]tx[)] \*/ sync_core.getScn[(]tx.scn, tx.ora_rowscn[)] scn, tx.ts event_timestamp, src.* FROM sy\$liar_job_relay_2 src, sy\$txlog tx WHERE src.txn=tx.txn AND tx.scn > ? AND tx.ora_rowscn > [?] AND  tx.ora_rowscn <= [?]; skipInfinityScn=false' ${relay_2_server_log} | wc -l | perl -lane '{ my $a = $_; chomp($a); if ($a <= 0 ) { print $a; exit 1; } else { exit 0;} }'
source report_pass_fail.inc

echo "Verifying if SCN Chunked Query was used for fetching liar_member_relay"
stat_txt="Verifying if SCN Chunked Query was used for fetching liar_member_relay"
grep  'SELECT /\*+ first_rows LEADING[(]tx[)] \*/ sync_core.getScn[(]tx.scn, tx.ora_rowscn[)] scn, tx.ts event_timestamp, src.* FROM sy\$liar_member_relay src, sy\$txlog tx WHERE src.txn=tx.txn AND tx.scn > ? AND tx.ora_rowscn > [?] AND  tx.ora_rowscn <= [?]; skipInfinityScn=false' ${relay_2_server_log} | wc -l | perl -lane '{ my $a = $_; chomp($a); if ($a <= 0 ) { print $a; exit 1; } else { exit 0;} }'
source report_pass_fail.inc

echo "Verifying if TXN Chunked Query was NOT used for fetching liar_job_relay"
stat_txt="Verifying if TXN Chunked Query was NOT used for fetching liar_job_relay"
grep 'SELECT scn, event_timestamp, src.\* FROM sy\$liar_job_relay_2 src, [(] SELECT /\*+ first_rows LEADING[(]tx[)] cardinality[(]tx,1[)] \*/  sync_core.getScn[(]tx.scn, tx.ora_rowscn[)] scn, tx.ts event_timestamp, tx.txn, row_number[(][)] OVER [(]ORDER BY TX.SCN[)] r FROM sy\$txlog tx WHERE tx.scn > [?] AND tx.ora_rowscn > [?] AND tx.scn < 9999999999999999999999999999[)] t WHERE src.txn = t.txn AND r<= [?] ORDER BY r ; skipInfinityScn=false' ${relay_2_server_log} | wc -l | perl -lane '{ my $a = $_; chomp($a); if ($a > 0 ) { print $a; exit 1; } else { exit 0;} }'
source report_pass_fail.inc

echo "Verifying if TXN Chunked Query was NOT used for fetching liar_member_relay"
stat_txt="Verifying if TXN Chunked Query was NOT used for fetching liar_member_relay"
grep 'SELECT scn, event_timestamp, src.\* FROM sy\$liar_member_relay src, [(] SELECT /\*+ first_rows LEADING[(]tx[)] cardinality[(]tx,1[)] \*/  sync_core.getScn[(]tx.scn, tx.ora_rowscn[)] scn, tx.ts event_timestamp, tx.txn, row_number[(][)] OVER [(]ORDER BY TX.SCN[)] r FROM sy\$txlog tx WHERE tx.scn > [?] AND tx.ora_rowscn > [?] AND tx.scn < 9999999999999999999999999999[)] t WHERE src.txn = t.txn AND r<= [?] ORDER BY r ; skipInfinityScn=false' ${relay_2_server_log} | wc -l | perl -lane '{ my $a = $_; chomp($a); if ($a > 0 ) { print $a; exit 1; } else { exit 0;} }'
source report_pass_fail.inc


stat_txt="Compare Relay1 and Consumer1 log"
echo ==$stat_txt :Compare JSON
$SCRIPT_DIR/dbus2_json_compare.py -s -c ${relay_event_dump_file_1} ${consumer_1_log} --fk_src_order=20,21
source report_pass_fail.inc

stat_txt="Compare Relay2 and Consumer2 log"
echo ==$stat_txt :Compare JSON
$SCRIPT_DIR/dbus2_json_compare.py -s -c ${relay_event_dump_file_2} ${consumer_2_log} --fk_src_order=20,21
source report_pass_fail.inc

stat_txt="Compare Relay3 and Consumer3 log"
echo ==$stat_txt :Compare JSON
$SCRIPT_DIR/dbus2_json_compare.py -s -c ${relay_event_dump_file_3} ${consumer_3_log} --fk_src_order=20,21
source report_pass_fail.inc

#compare result
stat_txt="Compare DB and consumer1 log"
echo ==$stat_txt 
$SCRIPT_DIR/dbus2_json_compare.py -s -c --sort_key --db_src_ids=20,21 --db_config_file=${db_config_file} ${consumer_1_value_log}
source report_pass_fail.inc

#compare result
stat_txt="Compare DB and consumer2 log"
echo ==$stat_txt 
$SCRIPT_DIR/dbus2_json_compare.py -s -c --sort_key --db_src_ids=20,21 --db_config_file=${db_config_file} ${consumer_2_value_log}
source report_pass_fail.inc

#compare result
stat_txt="Compare DB and consumer3 log"
echo ==$stat_txt 
$SCRIPT_DIR/dbus2_json_compare.py -s -c --sort_key --db_src_ids=20,21 --db_config_file=${db_config_file} ${consumer_3_value_log}
source report_pass_fail.inc

# stop
stat_txt="Stop Consumer"
$SCRIPT_DIR/dbus2_driver.py -c liar_consumer -o stop
source report_pass_fail.inc

$SCRIPT_DIR/dbus2_driver.py -c db_relay -o stop

final_report=1
stat_txt="Relay Pull Thread Validation"
cat ${VIEW_ROOT}/${WORK_DIR_FROM_ROOT}/*log* | perl $SCRIPT_DIR/validateRelayPullerMessageQueue.pl
source report_pass_fail.inc
exit $all_stat
