#!/bin/bash
#******************************************************
# relay_fault_close_on_stream_request
# set TEST_NAME before calling setup_env.inc
#******************************************************
export TEST_NAME=relay_fault_close_on_request.test
#******************************************************
# sets up common environmnet variables and 
source setup_env.inc

#########################################################################################################
#
# This testcase is for the bug DDS-1964
# When the relay closes the channel while in the middle of servicing the client request, 
#    the puller state machine goes to a "hung" state from which there is no progress.
#
# Instrumentation:
#   We have introduced a new relay type called "fault-relay" which can dynamically direct client
# request to fake RequestProcessors. In this case, a fake processor which closes the raw channel 
# on incoming request is used to reproduce the case
#
# Steps:
#  1. Bring up 2 databus2 relays (fault-relays)
#  2. Configure client with the 2 relays and infinite retries. start it.
#  3. Look at the client logs to see which is the relay that is selected by the client. ("client_selected_relay")
#  4. Generate events in client_selected_relay. 
#  5. Wait for the client to catchup. Verify the events between relay and client.
#  6. Now, load the "other_relay" with the events generated by client_selected_relay.
#  7. Also, generate few more events in "other_relay" with the starting SCN >= max_scn(client_selected_relay)
#  8. Send command to "client_selected_relay" to start faking stream requests. Now the "client_selected_relay" will close the channel. THis should make the client to connect to "other_relay" and start picking data.
#  9. Verify that client saw channel closed exceptions.
# 10. Also, verify if the client saw new events generated in "other_relay"
#
#
#########################################################################################################


#***************************************************************************************************************************************
#all ${ALL_CAPS} type vars come from setup_env.inc(except TEST_NAME)...check that file first before introducing any new variables here
#***************************************************************************************************************************************
relay_port_1=${RELAY_PORT_BASE}
let relay_port_2="${RELAY_PORT_BASE} + 1"
bootstrap_producer_port=${BOOTSTRAP_PRODUCER_PORT_BASE}
bootstrap_server_port=${BOOTSTRAP_SERVER_PORT_BASE}
client_port=${CLIENT_PORT_BASE}
relay_event_dump_file_1=${VIEW_ROOT}/${WORK_DIR_FROM_ROOT}/fault_relay_event_trace_1
relay_event_dump_file_2=${VIEW_ROOT}/${WORK_DIR_FROM_ROOT}/fault_relay_event_trace_2
relay_event_combined_file=${VIEW_ROOT}/${WORK_DIR_FROM_ROOT}/fault_relay_event_trace_combined
consumer_server_log=${VIEW_ROOT}/${LOG_DIR_FROM_ROOT}/liar_consumer_`date +%Y_%m_%d_%H_%M_%S`.log
consumer_log=${VIEW_ROOT}/${LOG_DIR_FROM_ROOT}/liar_consumer_event_trace
consumer_log_wo_picked_relay_last_scn=${VIEW_ROOT}/${LOG_DIR_FROM_ROOT}/liar_consumer_wo_picked_relay_last_scn_event_trace
num_consumers=1
consumers_start=0
range_size=1000

echo "Relay1 Port = ${relay_port_1}";
echo "Relay2 Port = ${relay_port_2}";

#start the relay 1
echo "Start Relay 1";
$SCRIPT_DIR/dbus2_driver.py -c fault_relay -o start --cmdline_props="databus.relay.httpRelay.eventBuffer.maxSize=10240000;databus.relay.httpRelay.eventBuffer.scnIndexSize=1024000;databus.relay.httpRelay.container.jmx.jmxServicePort=19998;databus.relay.httpRelay.eventBuffer.trace.option=file;databus.relay.httpRelay.eventBuffer.trace.filename=${relay_event_dump_file_1};databus.relay.httpRelay.eventBuffer.trace.appendOnly=false;databus.relay.httpRelay.container.httpPort=${relay_port_1};databus.relay.httpRelay.randomProducer.minLength=100;databus.relay.httpRelay.randomProducer.maxLength=101" --jvm_direct_memory_size=100M

#start the relay 2
echo "Start Relay 2";
$SCRIPT_DIR/dbus2_driver.py -c fault_relay -o start --cmdline_props="databus.relay.httpRelay.eventBuffer.maxSize=10240000;databus.relay.httpRelay.eventBuffer.scnIndexSize=1024000;databus.relay.httpRelay.container.jmx.jmxServicePort=19999;databus.relay.httpRelay.eventBuffer.trace.option=file;databus.relay.httpRelay.eventBuffer.trace.filename=${relay_event_dump_file_2};databus.relay.httpRelay.eventBuffer.trace.appendOnly=false;databus.relay.httpRelay.container.httpPort=${relay_port_2};databus.relay.httpRelay.randomProducer.minLength=100;databus.relay.httpRelay.randomProducer.maxLength=101" --jvm_direct_memory_size=100M

# start the consumer (with no upper limit of retries)
cp_dir=${VIEW_ROOT}/${WORK_DIR_FROM_ROOT}/ckpt
let client_port="${CLIENT_PORT_BASE}"
echo "Start Consumer ";
$SCRIPT_DIR/dbus2_driver.py -c liar_consumer -o start --logfile=${consumer_server_log} --http_port=${client_port} --dump_file=${consumer_log} --cmdline_props="databus.client.runtime.relay(2).name=DefaultRelay2;databus.client.runtime.relay(2).port=${relay_port_2};databus.client.runtime.relay(2).sources=com.linkedin.events.liar.jobrelay.LiarJobRelay,com.linkedin.events.liar.memberrelay.LiarMemberRelay;serversidefilter.filter(com.linkedin.events.liar.memberrelay.LiarMemberRelay).type=MOD;serversidefilter.filter(com.linkedin.events.liar.memberrelay.LiarMemberRelay).mod.numBuckets=1;serversidefilter.filter(com.linkedin.events.liar.memberrelay.LiarMemberRelay).mod.buckets=[0];serversidefilter.filter(com.linkedin.events.liar.jobrelay.LiarJobRelay).type=MOD;serversidefilter.filter(com.linkedin.events.liar.jobrelay.LiarJobRelay).mod.numBuckets=1;serversidefilter.filter(com.linkedin.events.liar.jobrelay.LiarJobRelay).mod.buckets=[0];databus.client.checkpointPersistence.fileSystem.rootDirectory=${cp_dir};databus.client.checkpointPersistence.clearBeforeUse=true;databus.client.connectionDefaults.pullerRetries.maxRetryNum=-1;databus.client.connectionDefaults.pullerRetries.sleepIncFactor=1;databus.client.connectionDefaults.pullerRetries.sleepIncDelta=0;databus.client.connectionDefaults.enablePullerMessageQueueLogging=true" 

#Consumer Picked Relay detection
consumer_picked_relay_port=`grep "picked a relay" ${consumer_server_log} | sed -n '$p' | sed -e 's/^.*port":\([0-9]\{1,\}\),.*$/\1/'`    # get the last one
if [ "${consumer_picked_relay_port}" == "${relay_port_1}" ]; then
  other_relay_port=${relay_port_2} 
  picked_relay_event_dump=${relay_event_dump_file_1}
  other_relay_event_dump=${relay_event_dump_file_2}
else
  other_relay_port=${relay_port_1} 
  picked_relay_event_dump=${relay_event_dump_file_2}
  other_relay_event_dump=${relay_event_dump_file_1}
fi

echo "consumer_picked_relay_port=${consumer_picked_relay_port}";
echo "other_relay_port=${other_relay_port}";

# Generate Event
echo "Generate Events for consumer";
$SCRIPT_DIR/dbus2_gen_event.py -s 20,21 -e 15000 --num_events=1000 --wait_until_suspend --server_port=${consumer_picked_relay_port}

sleep 10;

# Wait for the client to catchup
echo "Wait for the consumer to catchup";
$SCRIPT_DIR/dbus2_driver.py -c liar_consumer -o wait_event --timeout=60 --http_port=${client_port} --relay_port=${consumer_picked_relay_port} 

# Validate
echo "Compare JSON and Validate"
stat_txt="Test $0. Step 1 - Verify client events before switch"
$SCRIPT_DIR/dbus2_json_compare.py -s ${picked_relay_event_dump} ${consumer_log}
source report_pass_fail.inc

# save the event dump and reload into the second relay
cp ${picked_relay_event_dump} ${relay_event_combined_file}
picked_relay_event_load_file=${picked_relay_event_dump}_load
no_lines=`wc -l ${picked_relay_event_dump} | awk '{print $1}'`
end=$(($no_lines-10))
sed -n -e '1,'$end' p' ${picked_relay_event_dump} >${picked_relay_event_load_file}
picked_relay_last_scn=`sed -n -e '$p' ${picked_relay_event_dump} | sed -e 's/^.*"sequence":\([0-9]\{1,\}\),.*$/\1/'`

echo "Load Relay 1 event dump file to Relay 2. Loading from ${picked_relay_event_load_file}";
$SCRIPT_DIR/dbus2_gen_event.py -s 20,21 -f ${picked_relay_event_load_file} --server_port=${other_relay_port}

other_relay_start_scn=$((picked_relay_last_scn+500))
echo "Generating events from ${other_relay_start_scn}"
$SCRIPT_DIR/dbus2_gen_event.py -s 20,21 -e 15000 --num_events=500 --wait_until_suspend --server_port=${other_relay_port} --from_scn=${other_relay_start_scn}

#Command the picked relay to use fake stream processor which will close the connection on request
echo "Commanding relay to use Fake";
$SCRIPT_DIR/dbus2_driver.py -c fault_relay -o fake --relay_port=${consumer_picked_relay_port} --fake_cmd=stream

# Sleep for 5 sec and see you get errors in the client logs
echo "Sleep for 15 secs"
sleep 15;

## Now, Shutdown the first relay
#echo "Shutting down the consumer picked  relay";
#$SCRIPT_DIR/dbus2_driver.py -c fault_relay -o shutdown --http_port=${consumer_picked_relay_port}

# Wait for the client to catchup
echo "Expecting consumer 1 to switch to other relay and catchup"
$SCRIPT_DIR/dbus2_driver.py -c liar_consumer -o wait_event --timeout=60 --http_port=${client_port} --relay_port=${other_relay_port}
 
# look at the log
echo "Verifying that Client got Channel closed exception\n"
grep "Channel is closed even before finishing response" ${consumer_server_log} | wc -l | perl -lane '{ my $a = $_; chomp($a); if ($a == 0 ) { print $a; exit 1; } else { exit 0;} }'
source report_pass_fail.inc

# stop
echo "Stopping relay and consumer"
stat_txt="Stop Consumer"
$SCRIPT_DIR/dbus2_driver.py -c liar_consumer -o stop --http_port=${client_port}
source report_pass_fail.inc

$SCRIPT_DIR/dbus2_driver.py -c fault_relay -o stop

# Remove the repeated events while switching
grep -v "\"sequence\":${picked_relay_last_scn}" ${consumer_log} >  ${consumer_log_wo_picked_relay_last_scn}

# Validate
echo "Compare JSON and validate "
stat_txt="Test $0. Step 2 - Verify client events after switch"
$SCRIPT_DIR/dbus2_json_compare.py -s ${other_relay_event_dump} ${consumer_log_wo_picked_relay_last_scn}

stat_txt="Relay Pull Thread Validation"
cat ${VIEW_ROOT}/${WORK_DIR_FROM_ROOT}/*log* | perl $SCRIPT_DIR/validateRelayPullerMessageQueue.pl
source report_pass_fail.inc

exit $all_stat
