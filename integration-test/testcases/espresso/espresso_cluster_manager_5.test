#!/bin/bash
#******************************************************
# set TEST_NAME before calling setup_env.inc
#******************************************************
# There are two relays. Testing promotion to being a Leader when a Standby dies 
export TEST_NAME=espresso_cluster_manager_5.test
#******************************************************
# sets up common environmnet variables and 
source setup_env2.inc

#***************************************************************************************************************************************
#all ${ALL_CAPS} type vars come from setup_env.inc(except TEST_NAME)...check that file first before introducing any new variables here
#***************************************************************************************************************************************
client_port=${CLIENT_PORT_BASE}
relay_event_trace=${WORK_DIR_FROM_ROOT}/espresso_relay_event_trace
consumer_1_log=${WORK_DIR_FROM_ROOT}/espresso_consumer_1.events
consumer_1_value_log=${WORK_DIR_FROM_ROOT}/espresso_consumer_1.values
consumer_1_cp_dir=${WORK_DIR_FROM_ROOT}/ckpt/1
consumer_1_cp_dir_from_root=${VIEW_ROOT}/${WORK_DIR_FROM_ROOT}/ckpt/1
espresso_conf_dir=${CONFIG_DIR}/espresso
espressoDB_config_file_base=${espresso_conf_dir}/json/ppart__es_EspressoDB
espressoDB_list=EspressoDB
espressoDB_partitions=1
espressoDB_range=1
espressoDB_replicas=2
data_root=${VIEW_ROOT}/integration-test/data/testcases/espresso
data_file=${data_root}/EspressoDB_1.dat
jvm_direct_memory="-XX:MaxDirectMemorySize=200m"
jvm_min_heap="-Xms100m"
jvm_max_heap="-Xmx100m"
jvm_gc_args="-XX:+UseConcMarkSweepGC -XX:+UseParNewGC -XX:-CMSParallelRemarkEnabled -XX:MaxTenuringThreshold=1 -XX:SurvivorRatio=3 -XX:CMSInitiatingOccupancyFraction=85 -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintTenuringDistribution"
jvm_args="${jvm_direct_memory} ${jvm_min_heap} ${jvm_max_heap} ${jvm_new_size} ${gvm_gc_args}"

clusterName="relayIntTemp"
relay1Name="useLocalHostName_${relay1Port}"
relay2Name="useLocalHostName_${relay2Port}"
node1Name="$(hostname --long):${relay1Port}"
node2Name="$(hostname --long):${relay2Port}"
node1NameMod="$(hostname --long)_${relay1Port}"
node2NameMod="$(hostname --long)_${relay2Port}"
######### SETUP #########
# Setup espresso components
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c cluster_manager -o stop
$SCRIPT_DIR/dbus2_driver.py -n ${TEST_NAME} -c cluster_manager -o setup --db_list ${espressoDB_list} --db_range ${espressoDB_range} --db_replicas ${espressoDB_replicas} --zookeeper_server_hosts=${ZK_HOST} --zookeeper_server_ports=${ZK_PORT} --helix_clustername=${STORAGE_NODE_CLUSTER} --relay_zookeeper_server_hosts=${RELAY_ZK_HOST} --relay_zookeeper_server_ports=${RELAY_ZK_PORT}
echo '***** done setting up espresso components *****'


$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c cluster_manager -o invoke --cluster_manager_props="--addCluster ${clusterName} --zkSvr ${zkServer}"
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c cluster_manager -o invoke --cluster_manager_props="--listClusters --zkSvr ${zkServer}"
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c cluster_manager -o invoke --cluster_manager_props="--addNode ${clusterName} ${node1Name} --zkSvr ${zkServer}"
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c cluster_manager -o invoke --cluster_manager_props="--addNode ${clusterName} ${node2Name} --zkSvr ${zkServer}"
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c cluster_manager -o invoke --cluster_manager_props="--addResource ${clusterName} relayLeaderStandby 1 LeaderStandby --zkSvr ${zkServer}"
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c cluster_manager -o invoke --cluster_manager_props="--rebalance ${clusterName} relayLeaderStandby 2 --zkSvr ${zkServer}"
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c cluster_manager -o invoke --cluster_manager_props="--addResource ${clusterName} EspressoDB 1 OnlineOffline --zkSvr ${zkServer}"
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c cluster_manager -o start --helix_clustername=${clusterName} --zookeeper_server_hosts=${RELAY_ZK_HOST} --zookeeper_server_ports=${RELAY_ZK_PORT}
source report_pass_fail.inc

$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c cluster_admin_client -o start

sleep 30
echo "Expect relay1 to be leader because relay1 comes first in preference order"
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c cluster_admin_client -o checkLeader --cluster_name ${clusterName} --node_name ${node1NameMod} --check_ideal_state
source report_pass_fail.inc


$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c espresso_relay -o start --db_config_file=${espressoDB_config_file_base} --db_config_file_range=${espressoDB_partitions} --cmdline_props="databus.relay.eventBuffer.trace.filename=${relay_event_trace};databus.relay.eventBuffer.trace.appendOnly=false;databus.relay.container.httpPort=${relay1Port};databus.relay.clusterManager.instanceName=${relay1Name};databus.relay.container.tcp.port=${relay1TCPPort};databus.relay.clusterManager.relayClusterName=${clusterName}" -p ${espresso_conf_dir}/espresso_relay_cluster_manager_local.properties -l ${espresso_conf_dir}/espresso_relay_log4j.properties --jvm_args="${jvm_args}"
sleep 30

relay_pid1=$(jps | grep EspressoRelay | cut -d ' ' -f 1)
echo $relay_pid1

$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c espresso_relay -o start --db_config_file=${espressoDB_config_file_base} --db_config_file_range=${espressoDB_partitions} --cmdline_props="databus.relay.eventBuffer.trace.filename=${relay_event_trace};databus.relay.eventBuffer.trace.appendOnly=false;databus.relay.container.httpPort=${relay2Port};databus.relay.clusterManager.instanceName=${relay2Name};databus.relay.container.tcp.port=${relay2TCPPort};databus.relay.clusterManager.relayClusterName=${clusterName}" -p ${espresso_conf_dir}/espresso_relay_cluster_manager_local.properties -l ${espresso_conf_dir}/espresso_relay_log4j.properties --jvm_args="${jvm_args}"
sleep 30

echo "Expect relay1 to be leader because relay1 was the first relay to have come up"
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c cluster_admin_client -o checkLeader --cluster_name ${clusterName} --node_name ${node1NameMod}
source report_pass_fail.inc
kill -9 $relay_pid1
sleep 60
echo "Expect relay2 to be leader because relay1 was the killed"
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c cluster_admin_client -o checkLeader --cluster_name ${clusterName} --node_name ${node2NameMod}
source report_pass_fail.inc

$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c espresso_relay -o start --db_config_file=${espressoDB_config_file_base} --db_config_file_range=${espressoDB_partitions} --cmdline_props="databus.relay.eventBuffer.trace.filename=${relay_event_trace};databus.relay.eventBuffer.trace.appendOnly=false;databus.relay.container.httpPort=${relay1Port};databus.relay.clusterManager.instanceName=${relay1Name};databus.relay.container.tcp.port=${relay1TCPPort};databus.relay.clusterManager.relayClusterName=${clusterName}" -p ${espresso_conf_dir}/espresso_relay_cluster_manager_local.properties -l ${espresso_conf_dir}/espresso_relay_log4j.properties --jvm_args="${jvm_args}"

sleep 30
echo "Expect relay1 to be leader because relay1 was killed and brought back up"
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c cluster_admin_client -o checkLeader --cluster_name ${clusterName} --node_name ${node1NameMod} 
final_report=1
source report_pass_fail.inc
echo Number of failures = $all_stat

# Invoke twice to kill both the relays
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c espresso_relay -o stop
sleep 30
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c cluster_manager -o invoke --cluster_manager_props="--dropResource ${clusterName} ${espressoDB_list} --zkSvr ${RELAY_ZK_HOST}:${RELAY_ZK_PORT}"
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c cluster_manager -o invoke --cluster_manager_props="--dropResource ${clusterName} relayLeaderStandby --zkSvr ${RELAY_ZK_HOST}:${RELAY_ZK_PORT}"
sleep 5
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c cluster_manager -o invoke --cluster_manager_props="--dropCluster ${clusterName} --zkSvr ${RELAY_ZK_HOST}:${RELAY_ZK_PORT}"
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c cluster_admin_client -o stop
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c espresso_client -o stop
$SCRIPT_DIR/dbus2_driver.py -n ${TEST_NAME} -c cluster_manager -o teardown
######### TEARDOWN COMPLETE #########
exit $all_stat
