#!/bin/bash
#******************************************************
# Sets up the following topology on single box:
# 	* Espresso Router
# 	* Zoo Keeper
#	* Cluster Manager
# 	* Storage Node Cluster
#	* 2 Storage Nodes
# 	* Relay Cluster
# 	* 2 Relays, 2 rpl_dbus
# 	* 2 Relay clients
# 	* Schemas uploaded for EspressoDB, EspressoDB2, EspressoDB8
# 
# Testcase description : Turn ON relay and let it consume some events. Then turn it off. While relay is off, make a state transition on master partition (master -> offline),
# bring on the relay and validate that it picks up new state 
#******************************************************
export TEST_NAME=`basename $0` #espresso_relay_5_3_3_test7

# sets up common environment variables and 
source setup_env2.inc
#***************************************************************************************************************************************
#all ${ALL_CAPS} type vars come from setup_env.inc(except TEST_NAME)...check that file first before introducing any new variables here
#***************************************************************************************************************************************
espressoDB_list=EspressoDB  	#Can be a comma-separated list
espressoDB_range=1     	#Can be a comma-separated list
espressoDB_replicas=2 	#Can be a comma-separated list
clusterName=relayIntTemp
jvm_direct_memory="-XX:MaxDirectMemorySize=200m"
jvm_min_heap="-Xms100m"
jvm_max_heap="-Xmx100m"
jvm_gc_args="-XX:+UseConcMarkSweepGC -XX:+UseParNewGC -XX:-CMSParallelRemarkEnabled -XX:MaxTenuringThreshold=1 -XX:SurvivorRatio=3 -XX:CMSInitiatingOccupancyFraction=85 -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintTenuringDistribution"
jvm_args="${jvm_direct_memory} ${jvm_min_heap} ${jvm_max_heap} ${jvm_new_size} ${gvm_gc_args}"
client_port=${CLIENT_PORT_BASE}
relay_event_trace=${WORK_DIR_FROM_ROOT}/espresso_relay_event_trace
consumer_1_log=${WORK_DIR_FROM_ROOT}/espresso_consumer_1.events
consumer_1_value_log=${WORK_DIR_FROM_ROOT}/espresso_consumer_1.values
consumer_1_cp_dir=${WORK_DIR_FROM_ROOT}/ckpt/1
consumer_1_cp_dir_from_root=${VIEW_ROOT}/${WORK_DIR_FROM_ROOT}/ckpt/1
espresso_conf_dir=${CONFIG_DIR}/espresso
espressoDB_config_file_base=${espresso_conf_dir}/json/ppart__es_${espressoDB_list}
client_subs=espresso://MASTER/${espressoDB_list}/0/*,espresso://MASTER/${espressoDB_list}/1/*
data_root=${VIEW_ROOT}/integration-test/data/testcases/espresso
data_file=${data_root}/EspressoDB_Random1.dat
relay1_maxscn_dir=${VIEW_ROOT}/${WORK_DIR_FROM_ROOT}/maxScn1
relay2_maxscn_dir=${VIEW_ROOT}/${WORK_DIR_FROM_ROOT}/maxScn2
# Create the checkpoint directory
if [ ! -d ${consumer_1_cp_dir_from_root} ]; then
    mkdir -p ${consumer_1_cp_dir_from_root}
else
   rm -rf ${consumer_1_cp_dir_from_root}
   mkdir -p ${consumer_1_cp_dir_from_root}
fi 
#reset the relay maxscn
if [ ! -d ${relay1_maxscn_dir} ]; then
    mkdir -p ${relay1_maxscn_dir}
else
   rm -rf ${relay1_maxscn_dir}
   mkdir -p ${relay1_maxscn_dir}
fi 

if [ ! -d ${relay2_maxscn_dir} ]; then
    mkdir -p ${relay2_maxscn_dir}
else
   rm -rf ${relay2_maxscn_dir}
   mkdir -p ${relay2_maxscn_dir}
fi 

######### SETUP #########
# Setup espresso components
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c cluster_manager -o stop
$SCRIPT_DIR/dbus2_driver.py -n ${TEST_NAME} -c cluster_manager -o setup --db_list ${espressoDB_list} --db_range ${espressoDB_range} --db_replicas ${espressoDB_replicas} --zookeeper_server_hosts=${ZK_HOST} --zookeeper_server_ports=${ZK_PORT} --helix_clustername=${STORAGE_NODE_CLUSTER} --relay_zookeeper_server_hosts=${RELAY_ZK_HOST} --relay_zookeeper_server_ports=${RELAY_ZK_PORT}
echo '***** done setting up espresso components *****'

# Setup Relay Cluster
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c cluster_manager -o invoke --cluster_manager_props="--addCluster ${clusterName} --zkSvr ${RELAY_ZK_HOST}:${RELAY_ZK_PORT}"
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c cluster_manager -o invoke --cluster_manager_props="--listClusters --zkSvr ${RELAY_ZK_HOST}:${RELAY_ZK_PORT}" 
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c cluster_manager -o invoke --cluster_manager_props="--addNode ${clusterName} localhost:${relay1Port} --zkSvr ${RELAY_ZK_HOST}:${RELAY_ZK_PORT}"
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c cluster_manager -o invoke --cluster_manager_props="--addNode ${clusterName} localhost:${relay2Port} --zkSvr ${RELAY_ZK_HOST}:${RELAY_ZK_PORT}"
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c cluster_manager -o invoke --cluster_manager_props="--addResource ${clusterName} relayLeaderStandby 1 LeaderStandby --zkSvr ${RELAY_ZK_HOST}:${RELAY_ZK_PORT}"
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c cluster_manager -o invoke --cluster_manager_props="--rebalance ${clusterName} relayLeaderStandby 2 --zkSvr ${RELAY_ZK_HOST}:${RELAY_ZK_PORT}" 
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c cluster_manager -o invoke --cluster_manager_props="--addResource ${clusterName} ${espressoDB_list} ${espressoDB_range} OnlineOffline --zkSvr ${RELAY_ZK_HOST}:${RELAY_ZK_PORT}" 
echo '***** done creating relay cluster ***** '

#Start helix controller for relay cluster
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c cluster_manager -o start --helix_clustername=${clusterName} --zookeeper_server_hosts=${RELAY_ZK_HOST} --zookeeper_server_ports=${RELAY_ZK_PORT}
echo '***** done starting helix controller for relay cluster ***** '

#start 1 relay
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c espresso_relay -o start --db_config_file=${espressoDB_config_file_base} --db_config_file_range=${espressoDB_range} --cmdline_props="databus.relay.eventBuffer.trace.filename=${relay_event_trace}_${relay1Name};databus.relay.eventBuffer.trace.appendOnly=false;databus.relay.container.httpPort=${relay1Port};databus.relay.clusterManager.instanceName=${relay1Name};databus.relay.container.tcp.port=${relay1TCPPort};databus.relay.clusterManager.relayClusterName=${clusterName};databus.relay.clusterManager.relayZkConnectString=${RELAY_ZK_HOST}:${RELAY_ZK_PORT};databus.relay.dataSources.sequenceNumbersHandler.file.scnDir=${relay1_maxscn_dir}" -p ${espresso_conf_dir}/espresso_relay_cluster_manager_local.properties -l ${espresso_conf_dir}/espresso_relay_log4j.properties --jvm_args="${jvm_args}" 
echo '***** done creating first relay ***** '

######### SETUP COMPLETE#########
######## START TEST CASE ########

# Write events
stat_txt="Test $0: Write events "
$SCRIPT_DIR/dbus2_gen_event.py --espresso_gen --espresso_data_file=${data_file} --espresso_db_name=${espressoDB_list} --espresso_table_name=IdNamePair --num_events=100 --event_per_sec=100 --espresso_host=${EspressoRouter} --espresso_port=${EspressoRouterPort}
source report_pass_fail.inc

# Kill storage node 1, which hosts partition 0, Master, and do not bring it back up. 
stat_txt="Test $0: Killing StorageNode1 (12918) that hosts slave"
$SCRIPT_DIR/dbus2_driver.py -c espresso_storage_node -o stop_by_port --http_port=${SN2_PORT}
source report_pass_fail.inc

#start 1 relay back again ( will not come up fully as no storage node for it )
#$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c espresso_relay -o start --db_config_file=${espressoDB_config_file_base} --db_config_file_range=${espressoDB_range} --cmdline_props="databus.relay.eventBuffer.trace.filename=${relay_event_trace}_${relay1Name};databus.relay.eventBuffer.trace.appendOnly=false;databus.relay.container.httpPort=${relay1Port};databus.relay.clusterManager.instanceName=${relay1Name};databus.relay.container.tcp.port=${relay1TCPPort};databus.relay.clusterManager.relayClusterName=${clusterName};databus.relay.clusterManager.relayZkConnectString=${RELAY_ZK_HOST}:${RELAY_ZK_PORT};databus.relay.dataSources.sequenceNumbersHandler.file.scnDir=${relay1_maxscn_dir}" -p ${espresso_conf_dir}/espresso_relay_cluster_manager_local.properties -l ${espresso_conf_dir}/espresso_relay_log4j.properties --jvm_args="${jvm_args}" 

#TBD:


##### FINAL REPORT #####
stat_txt=""
final_report=1
source report_pass_fail.inc
echo Number of failures = $all_stat

######### TEARDOWN #########
echo Cleaning up...
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c espresso_relay -o stop
sleep 60
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c cluster_manager -o invoke --cluster_manager_props="--dropResource ${clusterName} ${espressoDB_list} --zkSvr ${RELAY_ZK_HOST}:${RELAY_ZK_PORT}"
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c cluster_manager -o invoke --cluster_manager_props="--dropResource ${clusterName} relayLeaderStandby --zkSvr ${RELAY_ZK_HOST}:${RELAY_ZK_PORT}"
sleep 5
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c cluster_manager -o invoke --cluster_manager_props="--dropCluster ${clusterName} --zkSvr ${RELAY_ZK_HOST}:${RELAY_ZK_PORT}"
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c cluster_admin_client -o stop
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c espresso_client -o stop
# Teardown espresso setup
$SCRIPT_DIR/dbus2_driver.py -n ${TEST_NAME} -c cluster_manager -o teardown
######### TEARDOWN COMPLETE #########

#echo == Looking for Error,ERROR or Exception in log files
#ls -1tr $LOG_DIR/esp* | xargs grep ERROR
#ls -1tr $LOG_DIR/esp* | xargs grep Error
#ls -1tr $LOG_DIR/esp* | xargs grep -i Exception
exit $all_stat

