#!/bin/bash
#******************************************************
# Sets up the following topology on single box:
# 	* Espresso Router
# 	* Zoo Keeper
#	* Cluster Manager
# 	* Storage Node Cluster
#	* 2 Storage Nodes
# 	* Relay Cluster
# 	* 2 Relays, 2 rpl_dbus
# 	* 2 Relay clients
# 	* Schemas uploaded for EspressoDB, EspressoDB2, EspressoDB8
# 
# set TEST_NAME before calling setup_env.inc
#******************************************************
export TEST_NAME=`basename $0` #espresso_dbusmgr_5_3_3_test6

# sets up common environmnet variables and 
source setup_env2.inc
source ${SCRIPT_DIR}/test_common.inc

#***************************************************************************************************************************************
#all ${ALL_CAPS} type vars come from setup_env.inc(except TEST_NAME)...check that file first before introducing any new variables here
#***************************************************************************************************************************************
espressoDB_list=EspressoDB8  	#Can be a comma-separated list
espressoDB_range=8     	#Can be a comma-separated list
espressoDB_replicas=1 	#Can be a comma-separated list
clusterName=relayIntTemp
jvm_direct_memory="-XX:MaxDirectMemorySize=200m"
jvm_min_heap="-Xms100m"
jvm_max_heap="-Xmx100m"
jvm_gc_args="-XX:+UseConcMarkSweepGC -XX:+UseParNewGC -XX:-CMSParallelRemarkEnabled -XX:MaxTenuringThreshold=1 -XX:SurvivorRatio=3 -XX:CMSInitiatingOccupancyFraction=85 -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintTenuringDistribution"
jvm_args="${jvm_direct_memory} ${jvm_min_heap} ${jvm_max_heap} ${jvm_new_size} ${gvm_gc_args}"
client_port=${CLIENT_PORT_BASE}
relay_event_trace=${WORK_DIR_FROM_ROOT}/espresso_relay_event_trace
consumer_1_log=${WORK_DIR_FROM_ROOT}/espresso_consumer_1.events
consumer_1_value_log=${WORK_DIR_FROM_ROOT}/espresso_consumer_1.values
consumer_1_cp_dir=${WORK_DIR_FROM_ROOT}/ckpt/1
consumer_1_cp_dir_from_root=${VIEW_ROOT}/${WORK_DIR_FROM_ROOT}/ckpt/1
espresso_conf_dir=${CONFIG_DIR}/espresso
espressoDB_config_file_base=${espresso_conf_dir}/json/ppart__es_${espressoDB_list}
client_subs=espresso://MASTER/${espressoDB_list}/0/*,espresso://MASTER/${espressoDB_list}/1/*,espresso://MASTER/${espressoDB_list}/2/*,espresso://MASTER/${espressoDB_list}/3/*,espresso://MASTER/${espressoDB_list}/4/*,espresso://MASTER/${espressoDB_list}/5/*,espresso://MASTER/${espressoDB_list}/6/*,espresso://MASTER/${espressoDB_list}/7/*
data_root=${VIEW_ROOT}/integration-test/data/testcases/espresso
data_file=${data_root}/EspressoDB_Random1.dat
relay1_maxscn_dir=${VIEW_ROOT}/${WORK_DIR_FROM_ROOT}/maxScn1
relay2_maxscn_dir=${VIEW_ROOT}/${WORK_DIR_FROM_ROOT}/maxScn2

# Create the checkpoint directory
CREATE_CLEAN_DIR ${consumer_1_cp_dir_from_root}
#reset the relay maxscn
CREATE_CLEAN_DIR ${relay1_maxscn_dir}
CREATE_CLEAN_DIR ${relay2_maxscn_dir}

LOG_INFO SETUP
# Uncomment this if you want the relay cluster and storage node clusters to be hosted on separate zookeeper instances
# export RELAY_ZK_PORT=2183


LOG_INFO Setup espresso components
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c cluster_manager -o stop
$SCRIPT_DIR/dbus2_driver.py -n ${TEST_NAME} -c cluster_manager -o setup --db_list ${espressoDB_list} --db_range ${espressoDB_range} --db_replicas ${espressoDB_replicas} --zookeeper_server_hosts=${ZK_HOST} --zookeeper_server_ports=${ZK_PORT} --helix_clustername=${STORAGE_NODE_CLUSTER} --relay_zookeeper_server_hosts=${RELAY_ZK_HOST} --relay_zookeeper_server_ports=${RELAY_ZK_PORT}
LOG_INFO 'done setting up espresso components'

LOG_INFO Delete RPL DBUS Threads
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c rpl_dbus -o delete_all_threads
LOG_INFO "done deleting rpl dbus threads"

LOG_INFO "Show Slave Status Output on mysql-rpl-dbus:"
mysql --defaults-file=/export/apps/mysql-rpl-dbus/my.cnf -uroot -e"show slave status\G;"
LOG_INFO "Show slave status Output on mysql-rpl-dbus2:"
mysql --defaults-file=/export/apps/mysql-rpl-dbus2/my.cnf -uroot -e"show slave status \G;"

TEST_STEP Setup Relay Cluster
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c cluster_manager -o invoke --cluster_manager_props="--addCluster ${clusterName} --zkSvr ${RELAY_ZK_HOST}:${RELAY_ZK_PORT}"
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c cluster_manager -o invoke --cluster_manager_props="--listClusters --zkSvr ${RELAY_ZK_HOST}:${RELAY_ZK_PORT}" 
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c cluster_manager -o invoke --cluster_manager_props="--addNode ${clusterName} localhost:${relay1Port} --zkSvr ${RELAY_ZK_HOST}:${RELAY_ZK_PORT}"
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c cluster_manager -o invoke --cluster_manager_props="--addNode ${clusterName} localhost:${relay2Port} --zkSvr ${RELAY_ZK_HOST}:${RELAY_ZK_PORT}"
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c cluster_manager -o invoke --cluster_manager_props="--addResource ${clusterName} relayLeaderStandby 1 LeaderStandby --zkSvr ${RELAY_ZK_HOST}:${RELAY_ZK_PORT}"
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c cluster_manager -o invoke --cluster_manager_props="--rebalance ${clusterName} relayLeaderStandby 2 --zkSvr ${RELAY_ZK_HOST}:${RELAY_ZK_PORT}" 
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c cluster_manager -o invoke --cluster_manager_props="--addResource ${clusterName} ${espressoDB_list} ${espressoDB_range} OnlineOffline --zkSvr ${RELAY_ZK_HOST}:${RELAY_ZK_PORT}" 
#$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c cluster_admin_client -o start --zookeeper_server_hosts=${RELAY_ZK_HOST} --zookeeper_server_ports=${RELAY_ZK_PORT}
#$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c cluster_admin_client -o checkLeader --cluster_name ${clusterName} --node_name ${relay1Name}
REPORT_TEST_STEP


LOG_INFO Start helix controller for relay cluster
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c cluster_manager -o start --helix_clustername=${clusterName} --zookeeper_server_hosts=${RELAY_ZK_HOST} --zookeeper_server_ports=${RELAY_ZK_PORT}
LOG_INFO 'done starting helix controller for relay cluster'

LOG_INFO start the 2 relays. Configure them to receive events from the EspressoDB8 schema. Register it to listen to the EV of the DevCluster_Dbus Espresso Storage Node Cluster 
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c espresso_relay -o start --db_config_file=${espressoDB_config_file_base} --db_config_file_range=${espressoDB_range} --cmdline_props="databus.relay.eventBuffer.trace.filename=${relay_event_trace}_${relay1Name};databus.relay.eventBuffer.trace.appendOnly=false;databus.relay.container.httpPort=${relay1Port};databus.relay.clusterManager.instanceName=${relay1Name};databus.relay.container.tcp.port=${relay1TCPPort};databus.relay.clusterManager.relayClusterName=${clusterName};databus.relay.clusterManager.relayZkConnectString=${RELAY_ZK_HOST}:${RELAY_ZK_PORT};databus.relay.dataSources.sequenceNumbersHandler.file.scnDir=${relay1_maxscn_dir}" -p ${espresso_conf_dir}/espresso_relay_cluster_manager_rplmanager_local.properties -l ${espresso_conf_dir}/espresso_relay_log4j.properties --jvm_args="${jvm_args}" 
LOG_INFO 'done creating first relay'

$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c espresso_relay -o start --db_config_file=${espressoDB_config_file_base} --db_config_file_range=${espressoDB_range} --cmdline_props="databus.relay.eventBuffer.trace.filename=${relay_event_trace}_${relay2Name};databus.relay.eventBuffer.trace.appendOnly=false;databus.relay.container.httpPort=${relay2Port};databus.relay.clusterManager.instanceName=${relay2Name};databus.relay.container.tcp.port=${relay2TCPPort};databus.relay.clusterManager.relayClusterName=${clusterName};databus.relay.clusterManager.relayZkConnectString=${RELAY_ZK_HOST}:${RELAY_ZK_PORT};databus.relay.dataSources.sequenceNumbersHandler.file.scnDir=${relay2_maxscn_dir}" -p ${espresso_conf_dir}/espresso_relay_cluster_manager_rplmanager_local2.properties -l ${espresso_conf_dir}/espresso_relay_log4j2.properties --jvm_args="${jvm_args}"
LOG_INFO 'done creating second relay'

LOG_INFO start the client and register it to receive events for EspressoDB8 all partitions
 $SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c espresso_client -o start --value_file=${consumer_1_value_log} --cmdline_props="databus.espresso.client.checkpointPersistence.fileSystem.rootDirectory=${consumer_1_cp_dir};databus.espresso.client.checkpointPersistence.clearBeforeUse=true;databus.espresso.client.connectionDefaults.eventBuffer.trace.filename=${consumer_1_log};databus.espresso.client.container.httpPort=${client_port};databus.espresso.client.clusterManager.relayClusterName=${clusterName};databus.espresso.client.subscriptions=${client_subs};databus.espresso.client.clusterManager.relayZkConnectString=${RELAY_ZK_HOST}:${RELAY_ZK_PORT}" -p ${espresso_conf_dir}/espresso_client_533.properties -l ${espresso_conf_dir}/espresso_client_log4j.properties --jvm_args="${jvm_args}"
LOG_INFO 'done creating first client'


LOG_INFO SETUP COMPLETE
LOG_INFO START TEST CASE
 
TEST_STEP Verify number of Registrations in client == number of partitions we specified
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c espresso_client -o verifyRegistrations --expected_num_registrations=8 --client_base_port_list=${client_port}
REPORT_TEST_STEP

LOG_INFO "Show Slave Status Output on mysql-rpl-dbus:"
mysql --defaults-file=/export/apps/mysql-rpl-dbus/my.cnf -uroot -e"show slave status\G;"
LOG_INFO "Show slave status Output on mysql-rpl-dbus2:"
mysql --defaults-file=/export/apps/mysql-rpl-dbus2/my.cnf -uroot -e"show slave status \G;"


TEST_STEP Verify threads created by rpl_dbus_mgr
sleep 30
stat_txt="Test $0: Check open rpl dbus threads on ${relay1Host}:${relay1Port}"
$SCRIPT_DIR/dbus3_verify.py --relay_rpldbus_nodes_verify --relay_host ${relay1Host} --relay_port ${relay1Port} --mysqlMaster localhost:3306
REPORT_TEST_STEP

TEST_STEP "Check open rpl dbus threads on ${relay2Host}:${relay2Port}"
$SCRIPT_DIR/dbus3_verify.py --relay_rpldbus_nodes_verify --relay_host ${relay2Host} --relay_port ${relay2Port} --mysqlMaster localhost:14100
REPORT_TEST_STEP

LOG_INFO Write events
$SCRIPT_DIR/dbus2_gen_event.py --espresso_gen --espresso_data_file=${data_file} --espresso_db_name=${espressoDB_list} --espresso_table_name=IdNamePair --num_events=100 --event_per_sec=100 --espresso_host=${EspressoRouter} --espresso_port=${EspressoRouterPort}

TEST_STEP wait for client to get caught up
$SCRIPT_DIR/dbus2_driver.py -c espresso_client -o wait_event_53 --relay_port=${relay1Port} --http_port=${client_port} --db_list=${espressoDB_list} --db_range=${espressoDB_range} --client_base_port_list=${client_port}
REPORT_TEST_STEP

TEST_STEP compare relay and client event logs
$SCRIPT_DIR/dbus2_json_compare.py --espresso_cluster_compare --file1=${relay_event_trace} --file2=${consumer_1_log} --db_list=${espressoDB_list} --db_range=${espressoDB_range} --client_host=${CLIENT_HOST} --client_port=${CLIENT_PORT_BASE} --master=True --slave=False --append=False
REPORT_TEST_STEP

TEST_STEP "Merge all logs into one file to ensure it is not zero"
$SCRIPT_DIR/dbus2_json_compare.py --cluster_merge --in=${relay_event_trace} --out=${relay_event_trace} --db_list=${espressoDB_list} --db_range=${espressoDB_range} --client_host=${CLIENT_HOST} --client_port=${CLIENT_PORT_BASE} --expected_event_count=100 --append=False
REPORT_TEST_STEP

TEST_STEP compare event and client values
$SCRIPT_DIR/dbus2_json_compare.py --espresso_value_compare --file1=${data_file} --file2=${consumer_1_value_log} --espresso_key_range=100 --espresso_host=${EspressoRouter} --espresso_port=${EspressoRouterPort} --db_list=${espressoDB_list} --db_range=${espressoDB_range}
REPORT_TEST_STEP

# Now bounce one of the relays
LOG_INFO "bouncing relay on port ${relay2Port} ..."
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c espresso_relay -o shutdown --http_port ${relay2Port}
sleep 5
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c espresso_relay -o start --db_config_file=${espressoDB_config_file_base} --db_config_file_range=${espressoDB_range} --cmdline_props="databus.relay.eventBuffer.trace.filename=${relay_event_trace}_${relay2Name};databus.relay.eventBuffer.trace.appendOnly=true;databus.relay.container.httpPort=${relay2Port};databus.relay.clusterManager.instanceName=${relay2Name};databus.relay.container.tcp.port=${relay2TCPPort};databus.relay.clusterManager.relayClusterName=${clusterName};databus.relay.clusterManager.relayZkConnectString=${RELAY_ZK_HOST}:${RELAY_ZK_PORT};databus.relay.dataSources.sequenceNumbersHandler.file.scnDir=${relay2_maxscn_dir}" -p ${espresso_conf_dir}/espresso_relay_cluster_manager_rplmanager_local2.properties -l ${espresso_conf_dir}/espresso_relay_log4j2.properties --jvm_args="${jvm_args}"
sleep 15

LOG_INFO "Writing events (after first bounce)"
$SCRIPT_DIR/dbus2_gen_event.py --espresso_gen --espresso_data_file=${data_file} --espresso_db_name=${espressoDB_list} --espresso_table_name=IdNamePair --num_events=100 --event_per_sec=100 --espresso_host=${EspressoRouter} --espresso_port=${EspressoRouterPort} --event_offset=100 

LOG_INFO wait for client to get caught up
$SCRIPT_DIR/dbus2_driver.py -c espresso_client -o wait_event_53 --relay_port=${relay1Port} --http_port=${client_port} --db_list=${espressoDB_list} --db_range=${espressoDB_range} --client_base_port_list=${client_port}

TEST_STEP "Merge all logs into one file to ensure it is not zero (after first bounce)"
##### Expect 201 events due to a bug in dbus manager where the last offset is sent twice #####
$SCRIPT_DIR/dbus2_json_compare.py --cluster_merge --in=${relay_event_trace} --out=${relay_event_trace} --db_list=${espressoDB_list} --db_range=${espressoDB_range} --client_host=${CLIENT_HOST} --client_port=${CLIENT_PORT_BASE} --expected_event_count=201 --append=False
REPORT_TEST_STEP

LOG_INFO Now remove a relay and add a different relay to the cluster  - we simulate this by removing the relays maxscn directory and relay log on rpl-dbus
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c espresso_relay -o shutdown --http_port ${relay2Port} #drop relay2
sleep 5
sudo -u app rm /export/apps/mysql-rpl-dbus2/data/*-relay-log.info
CREATE_CLEAN_DIR ${relay2_maxscn_dir}

$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c espresso_relay -o start --db_config_file=${espressoDB_config_file_base} --db_config_file_range=${espressoDB_range} --cmdline_props="databus.relay.eventBuffer.trace.filename=${relay_event_trace}_${relay2Name};databus.relay.eventBuffer.trace.appendOnly=true;databus.relay.container.httpPort=${relay2Port};databus.relay.clusterManager.instanceName=${relay2Name};databus.relay.container.tcp.port=${relay2TCPPort};databus.relay.clusterManager.relayClusterName=${clusterName};databus.relay.clusterManager.relayZkConnectString=${RELAY_ZK_HOST}:${RELAY_ZK_PORT};databus.relay.dataSources.sequenceNumbersHandler.file.scnDir=${relay2_maxscn_dir}" -p ${espresso_conf_dir}/espresso_relay_cluster_manager_rplmanager_local2.properties -l ${espresso_conf_dir}/espresso_relay_log4j2.properties --jvm_args="${jvm_args}"

$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c espresso_relay -o shutdown --http_port ${relay1Port} #drop relay1
sleep 5
sudo -u app rm /export/apps/mysql-rpl-dbus/data/*-relay-log.info
CREATE_CLEAN_DIR ${relay1_maxscn_dir}
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c espresso_relay -o start --db_config_file=${espressoDB_config_file_base} --db_config_file_range=${espressoDB_range} --cmdline_props="databus.relay.eventBuffer.trace.filename=${relay_event_trace}_${relay1Name};databus.relay.eventBuffer.trace.appendOnly=true;databus.relay.container.httpPort=${relay1Port};databus.relay.clusterManager.instanceName=${relay1Name};databus.relay.container.tcp.port=${relay1TCPPort};databus.relay.clusterManager.relayClusterName=${clusterName};databus.relay.clusterManager.relayZkConnectString=${RELAY_ZK_HOST}:${RELAY_ZK_PORT};databus.relay.dataSources.sequenceNumbersHandler.file.scnDir=${relay1_maxscn_dir}" -p ${espresso_conf_dir}/espresso_relay_cluster_manager_rplmanager_local.properties -l ${espresso_conf_dir}/espresso_relay_log4j.properties --jvm_args="${jvm_args}" 
sleep 60

TEST_STEP "Merge relay logs (after second bounce)"
##### Expect 201 events due to a bug in dbus manager where the last offset is sent twice #####
### 2nd bounce resets the relay log position - so we must expect more events in relay now since relay will fetch events for all 4 partitions it hosted
$SCRIPT_DIR/dbus2_json_compare.py --cluster_merge --in=${relay_event_trace} --out=${relay_event_trace} --db_list=${espressoDB_list} --db_range=${espressoDB_range} --client_host=${CLIENT_HOST} --client_port=${CLIENT_PORT_BASE} --expected_event_count=401 --append=True
REPORT_TEST_STEP


LOG_INFO FINAL REPORT
stat_txt=""
final_report=1
FINAL_TEST_REPORT
echo Number of failures = $all_stat

LOG_INFO TEARDOWN
echo Cleaning up...
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c espresso_relay -o stop
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c cluster_manager -o invoke --cluster_manager_props="--dropCluster ${clusterName} --zkSvr ${RELAY_ZK_HOST}:${RELAY_ZK_PORT}"
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c cluster_admin_client -o stop
$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c espresso_client -o stop
# Teardown espresso setup
$SCRIPT_DIR/dbus2_driver.py -n ${TEST_NAME} -c cluster_manager -o teardown
$SCRIPT_DIR/rpl_dbus_recreate_threads.bash
LOG_INFO TEARDOWN COMPLETE

#echo == Looking for Error,ERROR or Exception in log files
#ls -1tr $LOG_DIR/esp* | xargs grep ERROR
#ls -1tr $LOG_DIR/esp* | xargs grep Error
#ls -1tr $LOG_DIR/esp* | xargs grep -i Exception
exit $all_stat

