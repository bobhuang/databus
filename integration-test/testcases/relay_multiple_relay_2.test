#!/bin/bash
#******************************************************
# set TEST_NAME before calling setup_env.inc
#******************************************************
export TEST_NAME=relay_multiple_relay_2.test
#******************************************************
# Test multiple relays
#  -. start two relays
#  -. start event generation for the picked relay
#  -. make sure clients get the events
#  -. kill the picked relay
#  -. consumer should switch the other relay
#  -. load events from first relay into the second relay. generate event for the other relay.
#  -. make sure the consumer get the events
#  -. combine the relay event trace and compare with consumer dump, they should match
#  Q. How about if relay windows does not match, then the checkpoint scn may not 
# sets up common environmnet variables and 
source setup_env.inc

#***************************************************************************************************************************************
#all ${ALL_CAPS} type vars come from setup_env.inc(except TEST_NAME)...check that file first before introducing any new variables here
#***************************************************************************************************************************************
relay_port=${RELAY_PORT_BASE}
relay_port_1=${relay_port}
let relay_port_2="${relay_port}+1"
bootstrap_producer_port=${BOOTSTRAP_PRODUCER_PORT_BASE}
bootstrap_server_port=${BOOTSTRAP_SERVER_PORT_BASE}
client_port=${CLIENT_PORT_BASE}
relay_event_dump_file_1=${VIEW_ROOT}/${WORK_DIR_FROM_ROOT}/bizfollow_relay_event_trace_1
relay_event_dump_file_2=${VIEW_ROOT}/${WORK_DIR_FROM_ROOT}/bizfollow_relay_event_trace_2
relay_event_combined_file=${VIEW_ROOT}/${WORK_DIR_FROM_ROOT}/bizfollow_relay_event_trace_combined
relay_1_server_log=${VIEW_ROOT}/${LOG_DIR_FROM_ROOT}/bizfollow_relay_${relay_port_1}_`date +%Y_%m_%d_%H_%M_%S`.log
relay_2_server_log=${VIEW_ROOT}/${LOG_DIR_FROM_ROOT}/bizfollow_relay_${relay_port_2}_`date +%Y_%m_%d_%H_%M_%S`.log
consumer_1_log=${VIEW_ROOT}/${WORK_DIR_FROM_ROOT}/bizfollow_consumer_1.events
consumer_1_server_log=${VIEW_ROOT}/${LOG_DIR_FROM_ROOT}/bizfollow_consumer_1_`date +%Y_%m_%d_%H_%M_%S`.log
consumer_cp_dir=${WORK_DIR_FROM_ROOT}/consumer_checkpoint_bizfollow
#

# 10M buffer , event dump file 
$SCRIPT_DIR/dbus2_driver.py -c bizfollow_relay -o start --logfile=${relay_1_server_log} --cmdline_props="databus.relay.container.httpPort=${relay_port_1};databus.relay.container.jmx.jmxServicePort=19998;databus.relay.eventBuffer.maxSize=10240000;databus.relay.eventBuffer.scnIndexSize=1024000;databus.relay.eventBuffer.trace.option=file;databus.relay.eventBuffer.trace.filename=${relay_event_dump_file_1};databus.relay.eventBuffer.trace.appendOnly=false;databus.relay.randomProducer.minLength=180;databus.relay.randomProducer.maxLength=181;" --jvm_direct_memory_size=100M 

$SCRIPT_DIR/dbus2_driver.py -c bizfollow_relay -o start --logfile=${relay_2_server_log} --cmdline_props="databus.relay.container.httpPort=${relay_port_2};databus.relay.container.jmx.jmxServicePort=19999;databus.relay.eventBuffer.maxSize=10240000;databus.relay.eventBuffer.scnIndexSize=1024000;databus.relay.eventBuffer.trace.option=file;databus.relay.eventBuffer.trace.filename=${relay_event_dump_file_2};databus.relay.eventBuffer.trace.appendOnly=false;databus.relay.randomProducer.minLength=180;databus.relay.randomProducer.maxLength=181;" --jvm_direct_memory_size=100M

# start the consumer
$SCRIPT_DIR/dbus2_driver.py -c bizfollow_consumer -o start --dump_file=${consumer_1_log} --logfile=${consumer_1_server_log} --http_port=${client_port} --cmdline_props="databus.client.runtime.relay(2).name=DefaultRelay2;databus.client.runtime.relay(2).port=${relay_port_2};databus.client.runtime.relay(2).sources=com.linkedin.events.bizfollow.bizfollow.BizFollow;databus.client.checkpointPersistence.fileSystem.rootDirectory=${consumer_cp_dir};databus.client.checkpointPersistence.clearBeforeUse=true;databus.client.connectionDefaults.enablePullerMessageQueueLogging=true" -l ${CONFIG_DIR_FROM_ROOT}/client-log4j2file.properties

consumer_picked_relay_port=`grep "picked a relay" ${consumer_1_server_log} | sed -n '$p' | sed -e 's/^.*port":\([0-9]\{1,\}\),.*$/\1/'`    # get the last one
if [ "${consumer_picked_relay_port}" == "${relay_port_1}" ]; then
  other_relay_port=${relay_port_2} 
  picked_relay_event_dump=${relay_event_dump_file_1}
  other_relay_event_dump=${relay_event_dump_file_2}
else
  other_relay_port=${relay_port_1} 
  picked_relay_event_dump=${relay_event_dump_file_2}
  other_relay_event_dump=${relay_event_dump_file_1}
fi
# generate events
$SCRIPT_DIR/dbus2_gen_event.py -s 40 -e 15000 --num_events=40 --keyMin=1000 --keyMax=2000  --wait_until_suspend --server_port=${consumer_picked_relay_port}

# wait
$SCRIPT_DIR/dbus2_driver.py -c bizfollow_consumer -o wait_event --timeout=60 --relay_port=${consumer_picked_relay_port} --http_port=${client_port}

echo ==Compare JSON
stat_txt="Test $0. Step 1"
$SCRIPT_DIR/dbus2_json_compare.py -s ${picked_relay_event_dump} ${consumer_1_log}
source report_pass_fail.inc

# save the event dump and reload into the second relay
cp ${picked_relay_event_dump} ${relay_event_combined_file}
picked_relay_event_load_file=${picked_relay_event_dump}_load
no_lines=`wc -l ${picked_relay_event_dump} | awk '{print $1}'`
end=$(($no_lines-10))
sed -n -e '1,'$end' p' ${picked_relay_event_dump} >${picked_relay_event_load_file}
picked_relay_last_scn=`sed -n -e '$p' ${picked_relay_event_dump} | sed -e 's/^.*"sequence":\([0-9]\{1,\}\),.*$/\1/'`

echo "### Generating events on :${other_relay_port}"
$SCRIPT_DIR/dbus2_gen_event.py -s 40 -f ${picked_relay_event_load_file} --server_port=${other_relay_port}

# kill the first relay
echo "### Killing relay on :${consumer_picked_relay_port}"
$SCRIPT_DIR/dbus2_driver.py -c bizfollow_relay -o shutdown --http_port=${consumer_picked_relay_port}

other_relay_start_scn=$((picked_relay_last_scn-5))
# so the the consumer checkpoint scn should fall in the middle of the first window generated.
# consumer will replay the window before the checkpoint
echo "### Generating events on relay :${other_relay_port}"
$SCRIPT_DIR/dbus2_gen_event.py -s 40 -e 15000 --from_scn=500 --num_events=50 --keyMin=3000 --keyMax=4000 --wait_until_suspend --server_port=${other_relay_port}

echo "### Waiting for consumer to catch up with relay"
$SCRIPT_DIR/dbus2_driver.py -c bizfollow_consumer -o wait_event --timeout=60 --relay_port=${other_relay_port} --http_port=${client_port}

echo "Sleeping for 30 sec"
sleep 30

echo ==Please check ${consumer_1_log} and see if it gets any events from ${other_relay_event_dump}
# combine the relay trace
cat ${other_relay_event_dump}  >> ${relay_event_combined_file}

# stop
stat_txt="Stop Consumer"
$SCRIPT_DIR/dbus2_driver.py -c bizfollow_consumer -o stop
source report_pass_fail.inc
$SCRIPT_DIR/dbus2_driver.py -c bizfollow_relay -o stop

consumer_1_log_wo_picked_relay_last_scn=${consumer_1_log}_wo_picked_relay_last_scn
grep -v "\"sequence\":${picked_relay_last_scn}" ${consumer_1_log} >  ${consumer_1_log_wo_picked_relay_last_scn}

#compare result
echo ==Compare JSON
stat_txt="Test $0. Step 2"
# since we are reloading, the other relay also has the events
$SCRIPT_DIR/dbus2_json_compare.py -c -s ${other_relay_event_dump} ${consumer_1_log_wo_picked_relay_last_scn}
source report_pass_fail.inc

final_result=1
stat_txt="Relay Pull Thread Validation"
cat ${VIEW_ROOT}/${WORK_DIR_FROM_ROOT}/*log* | perl $SCRIPT_DIR/validateRelayPullerMessageQueue.pl
source report_pass_fail.inc

exit $all_stat
