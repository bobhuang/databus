#!/bin/bash
#******************************************************
# liar range filter test
# set TEST_NAME before calling setup_env.inc
#******************************************************
export TEST_NAME=liar_load_balanced_multiple_clients_clusters_rebalance.test
#******************************************************
# sets up common environmnet variables and 
source setup_env.inc
source ${SCRIPT_DIR}/test_common.inc

#***************************************************************************************************************************************
#all ${ALL_CAPS} type vars come from setup_env.inc(except TEST_NAME)...check that file first before introducing any new variables here
#***************************************************************************************************************************************
relay_port=${RELAY_PORT_BASE}
bootstrap_producer_port=${BOOTSTRAP_PRODUCER_PORT_BASE}
bootstrap_server_port=${BOOTSTRAP_SERVER_PORT_BASE}
client_port=${CLIENT_PORT_BASE}
relay_event_dump_file=${WORK_DIR_FROM_ROOT}/liar_relay_event_trace
relay_gc_file=${WORK_DIR_FROM_ROOT}/liar_relay_gc.log
cluster_name="liar_lb_test1"
cluster_name2="liar_lb_test2"
num_partitions=10
consumers_start=0
num_consumers=5
consumer_1_value_log=${WORK_DIR_FROM_ROOT}/liar_consumer_1.values

# Start ZK
zk_hostport="${ZK_HOST}:${ZK_PORT}"
LOG_INFO ZK Coordinates : ${zk_hostport}
$SCRIPT_DIR/dbus2_driver.py -n LIAR_LB_TEST1 -c zookeeper -o start --zookeeper_server_ports=${zk_hostport} --zookeeper_reset

#start the relay
$SCRIPT_DIR/dbus2_driver.py -c liar_relay -o start --jvm_args="-Xms24m -Xmx50m" --jvm_gc_log=${relay_gc_file} --cmdline_props="databus.relay.eventBuffer.maxSize=1024000;databus.relay.eventBuffer.trace.option=file;databus.relay.eventBuffer.trace.filename=${relay_event_dump_file};databus.relay.eventBuffer.trace.appendOnly=false;databus.relay.container.httpPort=${relay_port}"

# reset the db and delete the checkpoints
LOG_INFO Reset BootstrapDB
$SCRIPT_DIR/dbus2_driver.py -c bootstrap_dbreset

# start the producer, use a given port to avoid conflict with consumer
LOG_INFO Start Bootstrap Producer
$SCRIPT_DIR/dbus2_driver.py -c test_bootstrap_producer -o start --cmdline_props="databus.bootstrap.client.runtime.relay(1).sources=com.linkedin.events.liar.jobrelay.LiarJobRelay,com.linkedin.events.liar.memberrelay.LiarMemberRelay;databus.bootstrap.client.container.httpPort=9067;databus.bootstrap.client.checkpointPersistence.fileSystem.rootDirectory=./bootstrap-checkpoints;databus.bootstrap.client.checkpointPersistence.clearBeforeUse=true;databus.bootstrap.client.connectionDefaults.eventBuffer.maxSize=1024000;databus.bootstrap.client.connectionDefaults.eventBuffer.allocationPolicy=DIRECT_MEMORY;databus.bootstrap.client.connectionDefaults.eventBuffer.queuePolicy=BLOCK_ON_WRITE;databus.bootstrap.client.connectionDefaults.eventBuffer.readBufferSize=102400;databus.bootstrap.client.connectionDefaults.eventBuffer.scnIndexSize=102400;databus.bootstrap.client.container.httpPort=${bootstrap_producer_port};databus.bootstrap.client.runtime.relay(1).port=${relay_port};databus.bootstrap.client.connectionDefaults.pullerRetries.initSleep=10;databus.bootstrap.client.connectionDefaults.enablePullerMessageQueueLogging=true"

# generate events
# may need to break it to 80%, 40% if producer cannot catch up
$SCRIPT_DIR/dbus2_gen_event.py -s 20,21 -e 500 --percent_buff=80 --keyMin=0 --keyMax=9999 --wait_until_suspend --server_port=${relay_port}
# wait for producer to catch up
$SCRIPT_DIR/dbus2_driver.py -c test_bootstrap_producer -o producer_wait_event --timeout=40 --relay_port=${relay_port}

# wrap around the buffer to 80 + 40 = 120 percent
$SCRIPT_DIR/dbus2_gen_event.py -s 20,21 -e 500 --resume_gen --percent_buff=40 --keyMin=0 --keyMax=9999 --wait_until_suspend --server_port=${relay_port}

# Start Bootstrap Server
$SCRIPT_DIR/dbus2_driver.py -c bootstrap_server -o start --cmdline_props="databus.bootstrap.predicatePushDown=false;databus.bootstrap.db.container.httpPort=${bootstrap_server_port}"

# start the consumers
consumer_log=${WORK_DIR_FROM_ROOT}/liar_consumer.events
for (( i=$consumers_start; i<$num_consumers+$consumers_start; i++ ))
do
    cp_dir=${WORK_DIR_FROM_ROOT}/ckpt_${i}
    let client_port="${CLIENT_PORT_BASE} + ${i}"

   LOG_INFO "Sleep for 10 secs to mimic rolling start"
   sleep 10

    $SCRIPT_DIR/dbus2_driver.py -c liar_lb_consumer -o start --relay_port=${relay_port} --http_port=${client_port} --value_file=${consumer_1_value_log} --dump_file=${consumer_log} --bootstrap_port=${bootstrap_server_port}  --cluster_name="${cluster_name},${cluster_name2}" --cmdline_props="databus.client.clientCluster(1).clusterName=${cluster_name};databus.client.clientCluster(1).zkAddr=${zk_hostport};databus.client.clientCluster(1).numPartitions=${num_partitions};;databus.client.clientCluster(1).quorum=1;databus.client.clientCluster(2).clusterName=${cluster_name2};databus.client.clientCluster(2).zkAddr=${zk_hostport};databus.client.clientCluster(2).numPartitions=${num_partitions};;databus.client.clientCluster(2).quorum=1;;databus.client.checkpointPersistence.fileSystem.rootDirectory=${cp_dir};databus.client.checkpointPersistence.clearBeforeUse=true;databus.client.connectionDefaults.pullerRetries.initSleep=10;databus.client.connectionDefaults.enablePullerMessageQueueLogging=true" 
done

#Sleep for 15 secs
LOG_INFO "Sleeping for 15 secs"
sleep 15;

# check the consumers for cluster1
for (( i=$consumers_start; i<$num_consumers+$consumers_start; i++ ))
do
    let client_port="${CLIENT_PORT_BASE} + ${i}"
    $SCRIPT_DIR/dbus2_driver.py -c liar_lb_consumer -o wait_event_bootstrap --client_base_port_list=${client_port} --client_cluster_name=${cluster_name} --relay_port=${relay_port} --relay_host=localhost 
done

# check the consumers for cluster2
for (( i=$consumers_start; i<$num_consumers+$consumers_start; i++ ))
do
    let client_port="${CLIENT_PORT_BASE} + ${i}"
    $SCRIPT_DIR/dbus2_driver.py -c liar_lb_consumer -o wait_event_bootstrap --client_base_port_list=${client_port} --client_cluster_name=${cluster_name2} --relay_port=${relay_port} --relay_host=localhost 
done


# generate more events for clients to read from stream
$SCRIPT_DIR/dbus2_gen_event.py -s 20,21 -e 500 --resume_gen --percent_buff=40 --keyMin=0 --keyMax=9999 --wait_until_suspend --server_port=${relay_port}

#Sleep for 30 secs
LOG_INFO "Sleeping for 30 sec"
sleep 30;

# check consumers for cluster1
for (( i=$consumers_start; i<$num_consumers+$consumers_start; i++ ))
do
    let client_port="${CLIENT_PORT_BASE} + ${i}"
    LOG_INFO "Waiting for client $client_port"
    $SCRIPT_DIR/dbus2_driver.py -c liar_lb_consumer -o wait_event --client_base_port_list=${client_port} --client_cluster_name=${cluster_name} --relay_port=${relay_port} --relay_host=localhost
done

# check consumers for cluster2
for (( i=$consumers_start; i<$num_consumers+$consumers_start; i++ ))
do
    let client_port="${CLIENT_PORT_BASE} + ${i}"
    LOG_INFO "Waiting for client $client_port"
    $SCRIPT_DIR/dbus2_driver.py -c liar_lb_consumer -o wait_event --client_base_port_list=${client_port} --client_cluster_name=${cluster_name2} --relay_port=${relay_port} --relay_host=localhost
done

#Sleep for 10 sec
LOG_INFO "Sleeping for 10 sec"
sleep 10;

num_alive_clients=`jps | grep -c LiarLoadBalancedClient`;

LOG_INFO "Num Alive clients : ${num_alive_clients}";

# Check 5 clients are active
if [ ${num_alive_clients} -ne ${num_consumers} ]; then
  TEST_STEP Verify Active Clients
  LOG_INFO "FAIL : Num Alive Clients is : ${num_alive_clients}";
  echo "exit -1" | sh
  REPORT_TEST_STEP
fi

# Shutdown 2 clients
for (( i=0; i<2; i++ ))
do
    let client_port="${CLIENT_PORT_BASE} + ${i}"
    $SCRIPT_DIR/dbus2_driver.py -c liar_lb_consumer -o shutdown --http_port=${client_port}
done

LOG_INFO "sleep for 5 secs"
sleep 5

let exp_num_clients="${num_consumers} - 2"
num_alive_clients=`jps | grep -c LiarLoadBalancedClient`;
# Check 3 clients are active
if [ ${num_alive_clients} -ne ${exp_num_clients} ]; then
  TEST_STEP Verify Active Clients
  LOG_INFO "FAIL : Num Alive Clients is : ${num_alive_clients}";
  echo "exit -1" | sh
  REPORT_TEST_STEP
fi

# generate more events for clients to read from stream
$SCRIPT_DIR/dbus2_gen_event.py -s 20,21 -e 500 --resume_gen --percent_buff=30 --keyMin=0 --keyMax=9999 --wait_until_suspend --server_port=${relay_port}

#Sleep for 30 secs
LOG_INFO "Sleeping for 30 sec"
sleep 30;

# check alive consumers for cluster1
for (( i=2; i<$num_consumers+$consumers_start; i++ ))
do
    let client_port="${CLIENT_PORT_BASE} + ${i}"
    $SCRIPT_DIR/dbus2_driver.py -c liar_lb_consumer -o wait_event --client_base_port_list=${client_port} --client_cluster_name=${cluster_name} --relay_port=${relay_port} --relay_host=localhost
done

# check alive consumers for cluster2
for (( i=2; i<$num_consumers+$consumers_start; i++ ))
do
    let client_port="${CLIENT_PORT_BASE} + ${i}"
    $SCRIPT_DIR/dbus2_driver.py -c liar_lb_consumer -o wait_event --client_base_port_list=${client_port} --client_cluster_name=${cluster_name2} --relay_port=${relay_port} --relay_host=localhost
done

# look at the log
LOG_INFO ==GREP ERROR
ls -1tr $LOG_DIR/*liar_relay_start* | ${TAIL_PATH} -n 1 | xargs grep ERROR

# stop
LOG_INFO "Stop Consumer"
TEST_STEP "Stop Consumer"
$SCRIPT_DIR/dbus2_driver.py -c liar_lb_consumer -o stop
REPORT_TEST_STEP

$SCRIPT_DIR/dbus2_driver.py -c bootstrap_server -o stop
$SCRIPT_DIR/dbus2_driver.py -c test_bootstrap_producer -o stop
$SCRIPT_DIR/dbus2_driver.py -c liar_relay -o stop
$SCRIPT_DIR/dbus2_driver.py -n LIAR_LB_TEST1 -c zookeeper -o stop --zookeeper_server_ports=${zk_hostport} --zookeeper_reset

#compare result
LOG_INFO ==Compare JSON
stat_txt="Test $0"

LOG_INFO "Compare logs for Cluster 1"
for (( i=$consumers_start; i<$num_partitions+$consumers_start; i++ ))
do
    TEST_STEP "Cluster ${cluster_name} Partition $i events comparison"
    consumer_log=${WORK_DIR_FROM_ROOT}/liar_consumer.events_${cluster_name}_${i}
    $SCRIPT_DIR/dbus2_json_compare.py --sort_key -c -s --server_side_filter="type=mod;mod.numBuckets=${num_partitions};mod.buckets=[${i}]" $VIEW_ROOT/${relay_event_dump_file} ${consumer_log}
    REPORT_TEST_STEP
done

LOG_INFO "Compare logs for Cluster 2"
for (( i=$consumers_start; i<$num_partitions+$consumers_start; i++ ))
do
    TEST_STEP "Cluster ${cluster_name2} Partition $i events comparison"
    consumer_log=${WORK_DIR_FROM_ROOT}/liar_consumer.events_${cluster_name2}_${i}
    $SCRIPT_DIR/dbus2_json_compare.py --sort_key -c -s --server_side_filter="type=mod;mod.numBuckets=${num_partitions};mod.buckets=[${i}]" $VIEW_ROOT/${relay_event_dump_file} ${consumer_log}
    REPORT_TEST_STEP
done

TEST_STEP "Relay Pull Thread Validation"
cat ${VIEW_ROOT}/${WORK_DIR_FROM_ROOT}/*log* | perl $SCRIPT_DIR/validateRelayPullerMessageQueue.pl
REPORT_TEST_STEP

FINAL_TEST_REPORT
exit $all_stat
