#!/bin/bash
#******************************************************
# Test that a relay can run with a large buffer, both with and without HTTP compression.
#  - start member2relay with a property file config/relay-config-large-1.properties and no compression
#  - start client
#  - gen event, monitoring the buffer stats, freespace, etc
#  - shut down client and relay
#  - repeat above steps except with HTTP compression enabled
#  - compare network and CPU stats for uncompressed and compressed runs
#
#******************************************************
# set TEST_NAME before calling setup_env.inc
export TEST_NAME=relay_large_buffer_1.test
#******************************************************
# sets up common environment variables and [...?]
source setup_env.inc
source ${SCRIPT_DIR}/test_common.inc

#******************************************************************************
# all ${ALL_CAPS} type vars come from setup_env.inc (except TEST_NAME)...check
# that file first before introducing any new variables here
#******************************************************************************
relay_port=${RELAY_PORT_BASE}
bootstrap_producer_port=${BOOTSTRAP_PRODUCER_PORT_BASE}
bootstrap_server_port=${BOOTSTRAP_SERVER_PORT_BASE}
client_port=${CLIENT_PORT_BASE}
# random trace file is generated on the fly by the relay:
relay_event_trace=${WORK_DIR_FROM_ROOT}/profile_relay_event_trace
# an alternative to on-the-fly, random trace data is a ~simulated trace captured
# from a test relay (e.g., curl -s 'eat1-app131.stg:11183/stream?sources=404&output=json&size=250000000'
# > MemberProfile.data.json) and fed to dbus2_driver.py with the --file option
# (must be in JSON format only)
consumer_1_log=${WORK_DIR_FROM_ROOT}/profile_consumer_1.uncompressed.events
consumer_2_log=${WORK_DIR_FROM_ROOT}/profile_consumer_2.compressed.events
sar_system_stats_bin_log=${VIEW_ROOT}/${WORK_DIR_FROM_ROOT}/sar.out.bin.`date +"%Y%m%d-%T"`


# skip over spurious "java.lang.AssertionError:" at very beginning
echo ""
echo ""

LOG_INFO "starting sar for CPU-usage stats (bin log = ${sar_system_stats_bin_log})"
# this will run for 5 minutes by default; integration test reliably takes 3m 58s
# (optionally could use killall at end to terminate sar preemptively)
sar -o ${sar_system_stats_bin_log} 1 300 >/dev/null 2>&1 &
sleep 3

#==============================================================================
# do UNCOMPRESSED run first (enableHttpCompression=false)

# log the start time
t0=`date +"%s.%N"`
# precision doesn't work for subtraction and multiplication, so do manual
# rounding ("0.5 +") and truncation (sed, with extra rule to catch ".500000000"
# -> "" corner-case):
delta_ms=`echo "3 k \`date +"%s.%N"\` ${t0} - 1000 * 0.5 + n" | dc | sed 's/\..*//'`
LOG_INFO "(+${delta_ms} ms):  starting relay and consumer in UNCOMPRESSED mode"

$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c profile_relay -o start  --jvm_direct_memory_size=11g --cmdline_props="databus.relay.eventBuffer.maxSize=10240000000;databus.relay.eventBuffer.readBufferSize=1024000;databus.relay.eventBuffer.scnIndexSize=1024000;databus.relay.eventBuffer.trace.option=file;databus.relay.eventBuffer.trace.filename=${relay_event_trace};databus.relay.eventBuffer.trace.appendOnly=false;databus.relay.container.httpPort=${relay_port};databus.relay.container.enableHttpCompression=false"

# start the consumer
$SCRIPT_DIR/dbus2_driver.py -c profile_consumer -o start --http_port=${client_port} --relay_port=${relay_port} --dump_file=${consumer_1_log} --cmdline_props="databus.client.connectionDefaults.eventBuffer.maxSize=10240000;databus.client.connectionDefaults.eventBuffer.allocationPolicy=DIRECT_MEMORY;databus.client.connectionDefaults.eventBuffer.queuePolicy=BLOCK_ON_WRITE;databus.client.connectionDefaults.eventBuffer.readBufferSize=1024000;databus.client.connectionDefaults.eventBuffer.scnIndexSize=1024000;databus.client.checkpointPersistence.fileSystem.rootDirectory=./profileclient-checkpoints;databus.client.checkpointPersistence.clearBeforeUse=true;databus.client.connectionDefaults.enablePullerMessageQueueLogging=true"

delta_ms=`echo "3 k \`date +"%s.%N"\` ${t0} - 1000 * 0.5 + n" | dc | sed 's/\..*//'`
outbound_stats=`2>/dev/null curl http://localhost:${relay_port}/containerStats/outbound/total`
LOG_INFO "(+${delta_ms} ms):  ${outbound_stats}"
delta_ms=`echo "3 k \`date +"%s.%N"\` ${t0} - 1000 * 0.5 + n" | dc | sed 's/\..*//'`
LOG_INFO "(+${delta_ms} ms):  starting events-generation"
now_sar_start=`date +"%T"`

# generate events:  src_id ~ member2, 1000 events/sec, 30 sec
$SCRIPT_DIR/dbus2_gen_event.py -s 2 -e 1000 -t 30000 --server_port=${relay_port}

delta_ms=`echo "3 k \`date +"%s.%N"\` ${t0} - 1000 * 0.5 + n" | dc | sed 's/\..*//'`
outbound_stats=`2>/dev/null curl http://localhost:${relay_port}/containerStats/outbound/total`
outbytes_tmp=`echo "${outbound_stats}" | sed -e 's/^.*numBytes"://' -e 's/,.*//'`
LOG_INFO "(+${delta_ms} ms):  ${outbound_stats}"
delta_ms=`echo "3 k \`date +"%s.%N"\` ${t0} - 1000 * 0.5 + n" | dc | sed 's/\..*//'`
LOG_INFO "(+${delta_ms} ms):  consumer wait_event"

#sleep 6  more intelligent wait
$SCRIPT_DIR/dbus2_driver.py -c profile_consumer -o wait_event --sleep_before_wait=31 --timeout=200 --http_port=${client_port} --relay_port=${relay_port}

now_sar_end=`date +"%T"`
avg_cpu_uncompressed=`sar -f ${sar_system_stats_bin_log} -s ${now_sar_start} -e ${now_sar_end} | tail -1 | awk '{print $3, $5, $3+$5}'`
avg_cpu_uncompressed_total=`echo ${avg_cpu_uncompressed} | awk '{print $3}'`
delta_ms=`echo "3 k \`date +"%s.%N"\` ${t0} - 1000 * 0.5 + n" | dc | sed 's/\..*//'`
echo ""
LOG_INFO "(+${delta_ms} ms):  UNCOMPRESSED average total (user+system) CPU = ${avg_cpu_uncompressed_total}%"
echo ""
delta_ms=`echo "3 k \`date +"%s.%N"\` ${t0} - 1000 * 0.5 + n" | dc | sed 's/\..*//'`
outbound_stats=`2>/dev/null curl http://localhost:${relay_port}/containerStats/outbound/total`
LOG_INFO "(+${delta_ms} ms):  ${outbound_stats}"
delta_ms=`echo "3 k \`date +"%s.%N"\` ${t0} - 1000 * 0.5 + n" | dc | sed 's/\..*//'`
LOG_INFO "(+${delta_ms} ms):  sleeping 60 seconds"

sleep 60

delta_ms=`echo "3 k \`date +"%s.%N"\` ${t0} - 1000 * 0.5 + n" | dc | sed 's/\..*//'`
outbound_stats=`2>/dev/null curl http://localhost:${relay_port}/containerStats/outbound/total`
LOG_INFO "(+${delta_ms} ms):  ${outbound_stats}"

outbytes_tmp2=`echo "${outbound_stats}" | sed -e 's/^.*numBytes"://' -e 's/,.*//'`
outbytes_uncompressed=`echo "${outbytes_tmp2} ${outbytes_tmp} - p" | dc`
echo ""
LOG_INFO "(+${delta_ms} ms):  UNCOMPRESSED outbound bytes = ${outbytes_uncompressed}"
echo ""

delta_ms=`echo "3 k \`date +"%s.%N"\` ${t0} - 1000 * 0.5 + n" | dc | sed 's/\..*//'`
LOG_INFO "(+${delta_ms} ms):  checking for errors and shutting down consumer and relay"

# FIXME:  also report non-zero errorTotalCount, errorConnectCount,
#   errorTimeoutCount in outbound_stats?

# look at the (most recent) log
delta_ms=`echo "3 k \`date +"%s.%N"\` ${t0} - 1000 * 0.5 + n" | dc | sed 's/\..*//'`
LOG_INFO "(+${delta_ms} ms):  grep for 'ERROR' in relay log (UNCOMPRESSED case; informational only)"
ls -1tr $LOG_DIR/*profile_relay_start* | ${TAIL_PATH} -n 1 | xargs grep ERROR

# FIXME (BUG):  first step doesn't get numbered; prints with a blank:
TEST_STEP "Stop consumer (UNCOMPRESSED case)"
$SCRIPT_DIR/dbus2_driver.py -c profile_consumer -o stop
REPORT_TEST_STEP
$SCRIPT_DIR/dbus2_driver.py -c profile_relay -o stop

delta_ms=`echo "3 k \`date +"%s.%N"\` ${t0} - 1000 * 0.5 + n" | dc | sed 's/\..*//'`
LOG_INFO "(+${delta_ms} ms):  comparing UNCOMPRESSED result and validating relay pull-thread"

TEST_STEP "Compare JSON result (UNCOMPRESSED case)"
$SCRIPT_DIR/dbus2_json_compare.py -s ${relay_event_trace} ${consumer_1_log}
REPORT_TEST_STEP

# FIXME:  validateRelayPullerMessageQueue.pl just checks for appropriate state
#   changes, so "*log*" wildcard mostly works (barring previous failures,
#   anyway), but it gets less and less efficient with every additional test-run
#   added to ../var/log:  instead, target desired log file(s) precisely
TEST_STEP "Relay Pull Thread Validation (UNCOMPRESSED case)"
cat ${VIEW_ROOT}/${WORK_DIR_FROM_ROOT}/*log* | perl $SCRIPT_DIR/validateRelayPullerMessageQueue.pl
REPORT_TEST_STEP


sleep 5  # make sure everything got shut down (heh...we hope)

echo ""
echo ""
echo ""
echo "=============================================================================="
echo ""
echo ""
echo ""


#==============================================================================
# now do COMPRESSED run (enableHttpCompression=true)

# log the start time
t0=`date +"%s.%N"`
delta_ms=`echo "3 k \`date +"%s.%N"\` ${t0} - 1000 * 0.5 + n" | dc | sed 's/\..*//'`
LOG_INFO "(+${delta_ms} ms):  starting relay and consumer in COMPRESSED mode"

$SCRIPT_DIR/dbus2_driver.py -n $TEST_NAME -c profile_relay -o start  --jvm_direct_memory_size=11g --cmdline_props="databus.relay.eventBuffer.maxSize=10240000000;databus.relay.eventBuffer.readBufferSize=1024000;databus.relay.eventBuffer.scnIndexSize=1024000;databus.relay.eventBuffer.trace.option=file;databus.relay.eventBuffer.trace.filename=${relay_event_trace};databus.relay.eventBuffer.trace.appendOnly=false;databus.relay.container.httpPort=${relay_port};databus.relay.container.enableHttpCompression=true"

# start the consumer
$SCRIPT_DIR/dbus2_driver.py -c profile_consumer -o start --http_port=${client_port} --relay_port=${relay_port} --dump_file=${consumer_2_log} --cmdline_props="databus.client.connectionDefaults.eventBuffer.maxSize=10240000;databus.client.connectionDefaults.eventBuffer.allocationPolicy=DIRECT_MEMORY;databus.client.connectionDefaults.eventBuffer.queuePolicy=BLOCK_ON_WRITE;databus.client.connectionDefaults.eventBuffer.readBufferSize=1024000;databus.client.connectionDefaults.eventBuffer.scnIndexSize=1024000;databus.client.checkpointPersistence.fileSystem.rootDirectory=./profileclient-checkpoints;databus.client.checkpointPersistence.clearBeforeUse=true;databus.client.connectionDefaults.enablePullerMessageQueueLogging=true"

delta_ms=`echo "3 k \`date +"%s.%N"\` ${t0} - 1000 * 0.5 + n" | dc | sed 's/\..*//'`
outbound_stats=`2>/dev/null curl http://localhost:${relay_port}/containerStats/outbound/total`
LOG_INFO "(+${delta_ms} ms):  ${outbound_stats}"
delta_ms=`echo "3 k \`date +"%s.%N"\` ${t0} - 1000 * 0.5 + n" | dc | sed 's/\..*//'`
LOG_INFO "(+${delta_ms} ms):  starting events-generation"
now_sar_start=`date +"%T"`

# generate events:  src_id ~ member2, 1000 events/sec, 30 sec
$SCRIPT_DIR/dbus2_gen_event.py -s 2 -e 1000 -t 30000 --server_port=${relay_port}

delta_ms=`echo "3 k \`date +"%s.%N"\` ${t0} - 1000 * 0.5 + n" | dc | sed 's/\..*//'`
outbound_stats=`2>/dev/null curl http://localhost:${relay_port}/containerStats/outbound/total`
outbytes_tmp=`echo "${outbound_stats}" | sed -e 's/^.*numBytes"://' -e 's/,.*//'`
LOG_INFO "(+${delta_ms} ms):  ${outbound_stats}"
delta_ms=`echo "3 k \`date +"%s.%N"\` ${t0} - 1000 * 0.5 + n" | dc | sed 's/\..*//'`
LOG_INFO "(+${delta_ms} ms):  consumer wait_event"

#sleep 6  more intelligent wait
$SCRIPT_DIR/dbus2_driver.py -c profile_consumer -o wait_event --sleep_before_wait=31 --timeout=200 --http_port=${client_port} --relay_port=${relay_port}

now_sar_end=`date +"%T"`
avg_cpu_compressed=`sar -f ${sar_system_stats_bin_log} -s ${now_sar_start} -e ${now_sar_end} | tail -1 | awk '{print $3, $5, $3+$5}'`
avg_cpu_compressed_total=`echo ${avg_cpu_compressed} | awk '{print $3}'`
delta_ms=`echo "3 k \`date +"%s.%N"\` ${t0} - 1000 * 0.5 + n" | dc | sed 's/\..*//'`
echo ""
LOG_INFO "(+${delta_ms} ms):  COMPRESSED average total (user+system) CPU = ${avg_cpu_compressed_total}%"
echo ""
delta_ms=`echo "3 k \`date +"%s.%N"\` ${t0} - 1000 * 0.5 + n" | dc | sed 's/\..*//'`
outbound_stats=`2>/dev/null curl http://localhost:${relay_port}/containerStats/outbound/total`
LOG_INFO "(+${delta_ms} ms):  ${outbound_stats}"
delta_ms=`echo "3 k \`date +"%s.%N"\` ${t0} - 1000 * 0.5 + n" | dc | sed 's/\..*//'`
LOG_INFO "(+${delta_ms} ms):  sleeping 60 seconds"

sleep 60

delta_ms=`echo "3 k \`date +"%s.%N"\` ${t0} - 1000 * 0.5 + n" | dc | sed 's/\..*//'`
outbound_stats=`2>/dev/null curl http://localhost:${relay_port}/containerStats/outbound/total`
LOG_INFO "(+${delta_ms} ms):  ${outbound_stats}"

outbytes_tmp2=`echo "${outbound_stats}" | sed -e 's/^.*numBytes"://' -e 's/,.*//'`
outbytes_compressed=`echo "${outbytes_tmp2} ${outbytes_tmp} - p" | dc`
delta_ms=`echo "3 k \`date +"%s.%N"\` ${t0} - 1000 * 0.5 + n" | dc | sed 's/\..*//'`
echo ""
LOG_INFO "(+${delta_ms} ms):  COMPRESSED outbound bytes = ${outbytes_compressed}"
echo ""

TEST_STEP "compute differences between UNCOMPRESSED and COMPRESSED runs"
outbytes_diff=`echo "${outbytes_uncompressed} ${outbytes_compressed} - p" | dc`
if [ ${outbytes_uncompressed} -ne 0 ]; then
  outbytes_ratio=`echo "4 k ${outbytes_compressed} ${outbytes_uncompressed} / 100 * p" | dc | sed 's/0*$//'`
  outbytes_compression_ratio=`echo "4 k ${outbytes_diff} ${outbytes_uncompressed} / 100 * p" | dc | sed 's/0*$//'`
  outbytes_compression_ratio_int=`echo ${outbytes_compression_ratio} | sed 's/\..*$//'`
  test ${outbytes_compression_ratio_int} -gt 10
else
  outbytes_compression_ratio="[error:  divide-by-zero]"
  outbytes_ratio="[error:  divide-by-zero]"
  /bin/false
fi
REPORT_TEST_STEP
delta_ms=`echo "3 k \`date +"%s.%N"\` ${t0} - 1000 * 0.5 + n" | dc | sed 's/\..*//'`
LOG_INFO "(+${delta_ms} ms):  compression ratio (savings) = ${outbytes_compression_ratio}%"
LOG_INFO "(+${delta_ms} ms):  data ratio = ${outbytes_ratio}%"
echo ""
avg_cpu_diff=`echo "${avg_cpu_compressed_total} ${avg_cpu_uncompressed_total} - p" | dc`
avg_cpu_percentage_diff=`echo "4 k ${avg_cpu_diff} ${avg_cpu_uncompressed_total} / 100 * p" | dc | sed 's/0*$//'`
LOG_INFO "(+${delta_ms} ms):  compression CPU cost = +${avg_cpu_diff} percentage points = +${avg_cpu_percentage_diff}% (average across all cores for duration of main event-generation)"
echo ""

LOG_INFO "(+${delta_ms} ms):  ${outbound_stats}"
delta_ms=`echo "3 k \`date +"%s.%N"\` ${t0} - 1000 * 0.5 + n" | dc | sed 's/\..*//'`
LOG_INFO "(+${delta_ms} ms):  checking for errors and shutting down consumer and relay"

# FIXME:  also report non-zero errorTotalCount, errorConnectCount,
#   errorTimeoutCount in outbound_stats?

# look at the (most recent) log
LOG_INFO "(+${delta_ms} ms):  grep for 'ERROR' in relay log (UNCOMPRESSED case; informational only)"
ls -1tr $LOG_DIR/*profile_relay_start* | ${TAIL_PATH} -n 1 | xargs grep ERROR

TEST_STEP "Stop consumer (COMPRESSED case)"
$SCRIPT_DIR/dbus2_driver.py -c profile_consumer -o stop
REPORT_TEST_STEP
$SCRIPT_DIR/dbus2_driver.py -c profile_relay -o stop

delta_ms=`echo "3 k \`date +"%s.%N"\` ${t0} - 1000 * 0.5 + n" | dc | sed 's/\..*//'`
LOG_INFO "(+${delta_ms} ms):  comparing COMPRESSED result and validating relay pull-thread"

TEST_STEP "Compare JSON result (COMPRESSED case)"
$SCRIPT_DIR/dbus2_json_compare.py -s ${relay_event_trace} ${consumer_2_log}
REPORT_TEST_STEP

# FIXME:  validateRelayPullerMessageQueue.pl just checks for appropriate state
#   changes, so "*log*" mostly works (barring previous failures, anyway), but
#   it gets less and less efficient with every additional test-run added to
#   ../var/log:  instead, target desired log files more precisely
TEST_STEP "Relay Pull Thread Validation (COMPRESSED case)"
cat ${VIEW_ROOT}/${WORK_DIR_FROM_ROOT}/*log* | perl $SCRIPT_DIR/validateRelayPullerMessageQueue.pl
FINAL_TEST_REPORT


delta_ms=`echo "3 k \`date +"%s.%N"\` ${t0} - 1000 * 0.5 + n" | dc | sed 's/\..*//'`
LOG_INFO "(+${delta_ms} ms):  done."

#==============================================================================

# Optionally could terminate sar here ("killall sar" or equivalent), but not
# critical to do so.  Could cut sar duration from 300s to 250s, though (test
# reliably executes in 238s on HP Z800 desktop).


exit $all_stat
